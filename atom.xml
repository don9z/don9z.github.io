<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Extra Cookies</title>
  
  <subtitle>By Dong ZHENG</subtitle>
  <link href="http://blog.zhengdong.me/atom.xml" rel="self"/>
  
  <link href="http://blog.zhengdong.me/"/>
  <updated>2021-11-06T03:53:49.411Z</updated>
  <id>http://blog.zhengdong.me/</id>
  
  <author>
    <name>Dong Zheng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>重读王慧文的清华产品课</title>
    <link href="http://blog.zhengdong.me/2021/11/03/the-product-lesson-of-wanghw/"/>
    <id>http://blog.zhengdong.me/2021/11/03/the-product-lesson-of-wanghw/</id>
    <published>2021-11-03T15:05:44.000Z</published>
    <updated>2021-11-06T03:53:49.411Z</updated>
    
    <content type="html"><![CDATA[<p>这几天晚上，又把王慧文的清华产品课文稿看了遍，每读必要收获，这里做些摘要。</p><h2 id="前言">前言</h2><p>产品经理是一个需要终身学习的职业，如果固化自己的知识体系和发展方向，是不太可能有太高成就。产品经理的核心能力是关于方法论，如果能掌握正确的方法论，就具备了跨领域的通用性。</p><blockquote><p>产品经理是一个需要终身学习的职业，想学一门专业的技术，一段时间后就只用好这门技术，或者专业能力只局限在一个领域，就不容易做好产品经理。<strong>产品经理是一个跨领域的专业，需要解决很多新的问题，如果固化自己的知识体系和发展方向，就不太可能在产品经理这个领域有太高的成就。</strong></p><p><strong>产品经理这个岗位是强专用性和强通用性同时存在的</strong>。<strong>专用性上</strong>，例如电商产品经理和游戏产品经理的专业差别很大，美团阿里腾讯都有产品经理，但他们的专用技能差别很大。 在一个领域很成功的产品经理换一个领域，他的工作方法可能就不灵了。<strong>通用性</strong>也是很强的，例如Neil做肥皂和做国防部长，这两件事差别很大，但如果产品经理能掌握其中最关键的通用能力，就能快速上手其他的行业。</p><p><strong>产品经理的核心能力是关于方法论的，正确的思考方法、正确的沟通方法、正确的工作方法、正确的认知方法、正确的学习方法，如果能掌握正确的方法论，那就具有了跨领域的通用性。</strong>这也是Pichai(作为一个 冶金专业的人)和Google(作为一家搜索引擎为主的公司)能做好Chrome的意义，这说明他们的通用性能力很强。</p><p>产品经理是CEO的学前班，Pichai和Neil都不是专业出身最后成为CEO，但前提是你要有做创业产品经理的心态和思维。</p></blockquote><h2 id="战略">战略</h2><p>战略是不同时空里ROI最高的Strategy。 空间有多个含义，不同的地区是空间，不同的业务也是空间。制定战略要考虑如下11个因素。</p><blockquote><p>一、市场体量 (TAM: Total Addressable Market)：那么如果只能看一个要素，我们看什么要素呢? 就是这个行业的体量。</p><p>二、规模效应：规模效应是商业世界里的万有引力，<strong>老王认为今天的规模效应是交易额/客户使用量足够大之后所产生的客户体验优势或成本优势， 具体是成本优势还是客户体验优势取决于具体的生意模式</strong>。</p><ol type="1"><li>规模效应曲线的形状<ul><li><strong>指数曲线</strong>，是最典型的是网络效应，有网络效应的一个例子是互联网本身，公式是互联网的价值和节点数的平方成正比。外卖肯定不具备网络效应，有网络效应的生意最典型的例子是社交网络，微信是一个非常典型的网状结构，一个生意有没有规模效应是决定这个生意能做到多大和做到最后市场格局的关键因素。</li><li><strong>线性曲线</strong>，是淘宝，每多一个用户淘宝都能接纳，淘宝就增加一点价值，但用户和用户之间没啥竞争，所以淘宝的价值是随着规模线性上升的。这解释了很多问题，淘宝做到今天它的竞争对手是在变多的，淘宝2003年起家，2010年京东发展得很快，现在拼多多发展得很快，你已经做的这么大了还有竞争对手不断进来这就说明了你的规模效应不够强，没有在成本或体验上和后进者拉开巨大的差距。</li><li><strong>对数曲线</strong>的生意一般具有“<strong>双边网络且同边负效应</strong>”，外卖和淘宝是比较典型的双边网络，它不是完全节点的网络，但不见得所有的双边网络都存在同边负向效应，例如淘宝的供给非常充分接近无限供给，一个用户买一个商品不会影响另一个用户的购买，但你打个车对旁边的人就是有影响的，司机端也是一样，单子被抢走了就没了，所以打车就是双边的同边负向竞争。外卖的规模效应比打车稍 好一些，毕竟外卖的同边负效应比较低，商家的服务能力弹性大，配送员也有比较强的拼单能力，但是外卖跟京东比规模效应就弱些。</li></ul></li><li>规模效应的Scope<ul><li>规模效应是在多大的scope里(多大范围内)起作用。比如说全球型的规模效应，还是一个城市型的规模效应，<strong>规模效应的曲线形状和起作用的scope决定了很多生意的市场格局</strong>。</li></ul></li><li>规模效应曲线的参数<ul><li>说即便是线性增长，我的斜率也可大可小，即便是指数增长，也有参数大小。</li></ul></li><li>要素的规模效应<ul><li>所以很多要素之间是博弈的关系的，首先你要知道各个要素之间有博弈，其次你管理能力要强，再次你要知道合适的点在哪里，这个点就是试出来的。</li></ul></li></ol><p>三、马太效应</p><ul><li>马太效应的来源是圣经的《马太福音》“凡有的，还要加倍给他叫他多余;没有的，连他所有的也要夺过来”。马太效应是商业世界的进化论。<strong>几乎所有的领域，大部分决策者都没有有效的信息、知识结构和判断方法出独立判断，所以大家只能依赖专家或者从众因此产生马太效应。所以我们要尽可能抓住有规模效应的要素，尽可能减少反规模效应，尽快形成马太效应</strong>。</li></ul><p>四、市场集中度</p><ul><li>市场体量可以很大，如果市场集中度不够高的话，也产生不了很大的企业，典型的行业是餐饮，尤其是中国的餐饮行业。</li><li>市场集中度一般用CR，例如CR3表示行业里最大的3家的市占率，比如中国电信行业的CR3 就是100%，这是方法之一。</li></ul><p>五、产业链</p><ul><li><strong>每个产业链都有链主，链主才是这个行业里生存最好的角色，也在产业变革中是更有主动权的一方</strong>。比如电脑这个行业的链主是微软，如果你在这个产业链里不够强势，会导致在产业发生变化的时候你可能比较被动。比如微软现在做云计算，云计算意味着CPU和操作系统不直接卖了，而是放在云上卖。</li><li>在产业链关系里，市场集中度又影响到了上下游之间的产业链关系。<strong>对一家公司而言，最好的情况是上下游的集中度都很分散，就只有你的集中度很高，不过这种运气不是总有</strong>。</li></ul><p>六、先发与后发</p><ul><li>后发优势之一就是，你不需要去说服很多人了，先发者要去说服很多人的痛苦是很多人完全不能想象的。</li><li>后发者的第二个优势是知道这个事情一定能实现了。</li><li>后发者的第三个优势是后发者通常是比较常规的商业思维，而创新者通常思维是很独特的，但也因此带来了认知盲区。</li></ul><p>七、增量与存量</p><ul><li>存量市场虽然并非没有机会，但存量市场的发展实在是太难了，尤其是对后发者而言，最好还是在增量市场去发展。</li><li><strong>衡量增量存量的一个标准就是渗透率。在互联网生意里，增量和存量市场的获客成本的差别起码是十倍，这导致进入存量市场单单一个用户获取成本就会导致这个生意不成立</strong>。</li><li>所以<strong>存量市场也是有机会的，这很大程度上取决于你在多大程度上和第一名做差异化。记住迈克波特三战略：成本领先、差异化、专注</strong>。</li></ul><p>八、高频低频</p><ul><li>互联网一个常用的策略就是高频打低频，高频APP打低频APP就具备优势。</li></ul><p>九、入场时机</p><ul><li>天时大于地利，地利大于人和。这和孟子说的“天时不如地利，地利不如人和”是完全相反的。</li><li>如何判断和把握时机，但越重要的事情越难判断。老王借用了马克安德森的结论，<strong>如果你相信一件事早晚会发生，你就每3年试一次；老王自己的结论是，只要你没有倒闭，就是早入场比晚入场好，但怎么扛住别倒闭这件事对大公司和小公司都很难</strong>。</li><li><strong>所以为什么说只要你能确定公司不倒闭，越早入场越好，因为越早入场你越能积累正确认知，你越可能把握住浪潮。</strong>如果有一天创业也好还是在公司内搞个新业务也好，千万不要说兄弟们机会来了这次搞一把大的，那你多半会掉到坑里；你要想着兄弟们我们相信这个领域早晚会成，我们要一直干下去直到这个行业成功。</li></ul></blockquote><blockquote><p>十、迈克波特三战略</p><ul><li><strong>成本领先 (Cost Leadership)、差异化 (Differentiation)、聚焦 (Focus)</strong>。 注意！迈克波特三战略虽然很经典，但是需要强调一下的是<strong>这个三战略毕竟只是“竞争” 的三战略，而竞争只是商业中的一部分，甚至是不大的一部分</strong>。</li></ul><p>十一、标准化战略和有效战略</p><ul><li><strong>Strategy 应该是很多个要素叠加在一起才能形成一个有效的战略，如果一个简单的一两条战略就能有效的话，就证明你的业务经营、组织情况、产业状况还没到深水区。</strong></li></ul></blockquote><h2 id="strategy-for-product">Strategy for Product</h2><p>PMF，创新的扩散，STP和4P理论。</p><blockquote><p>一、PMF</p><ul><li>PMF (Product Market Fit) 最早是Benchmark Capital提出来的，马克安德森发扬光大。这个概念直译过来是产品匹配一个市场，或<strong>为市场匹配一个产品</strong>。老王认为后者更正确些。<strong>无论你是要做一个多大的市场，最开始都需要找一个更锐利的切入点切入市场，这个PMF选择的越犀利，那早期的ROI就越高，成功的概率就越高；注意这是找切入点，而不是最终目标市场</strong>。</li></ul><p>二、《创新的扩散》</p><ul><li>第一阶段是创新者Innovator，第二阶段是Early Adopter，绝大部分早期产品由于团队资源不足产品做得不太好。早期应用的人是非常小众的，<strong>早期产品的特点是简单粗暴有效，“简单粗暴”背后的“有效”能实现的前提是为什么在这个时间点能实现了， 为什么这个时间点这个需求出现了，是因为出现了突破点，其他的功能做不做没用</strong>。</li><li>而到 Early Adopter这个阶段就出现变化了，产品的易用性开始重要了，产品一开始易用性很差，乔布斯在PC发展史中很重要的一个贡献是图形界面，图形界面让电脑的易用性大幅提升使用门槛降低了，这是从Innovator到Early adopter到Early Majority阶段的易用性变化。所以我们知道什么因素导致这件事可行非常重要，我们只有在关键变化导致的可行要素里， 抓住关键点来推动这件事，然后投入足够多资源来把它最大化，我们的产品才能做得足够犀利。</li><li><strong>如果大家做一个新的产品或一个新的公司，你一定是在创新，你一定要先找到Early Adopter，你要用正确的Segment来找这些人， 无论你做一个多大的市场多通用的产品，你也要在最初的时候有一些Innovator或Early Adopter，否则会因为产品、资源、人力控制不住而失败</strong>。</li><li>年龄就是一个重要的维度，英国科幻作家道格拉斯·亚当斯有个很幽默的科技三定律：“<strong>任何在我出生时已经有的科技都是稀松平常的世界本来秩序的一部分；任何在我15-35岁之间诞生的科技都是将会改变世界的革命性产物；任何在我35岁之后诞生的科技是违反自然规律要遭天谴的！</strong>“</li></ul><p>三、<strong>STP (Segmenting、Targeting、Positioning)，S是对市场做划分，分成很多块，T是在划分完的市场里选一块作为目标市场，P是市场和产品(供给端)的认知连接</strong>。STP是一个很重要的PMF的方法论。</p><ol type="1"><li>Segmenting: 我们首先要对市场做划分。首先要选择正确的坐标系来划分市场，很多事情难解决可能就是坐标系选错了。</li><li>Targeting: 第二个是Targeting，但<strong>绝对不是Segmenting搞完了再搞Targeting这样的流水线作业方式，有时候是Targeting找不到好的目标回过头来重新做Segmenting。T如果找不到可能是S的维度没找好或者颗粒度不对。找T的时候，要清楚自己在找切入点还是找目标市场空间，这个差别是很大的，比如校内网的切入点是校园市场，但目标市场还是所有的人群</strong>。</li><li>Positioning: <strong>Positioning是对于用户来说，你的产品是什么，用户为什么要选你的产品</strong>。在T和P的关系上，<strong>T更偏需求和客户而P更偏供给和产品</strong>。延伸到产品上来讲，做产品非常重要的一件事是为什么要搞产品，<strong>只有知道为什么搞这个产品，才能把需求(Needs)解决地犀利，只有知道战略是什么，才能让产品匹配战略</strong>。</li></ol><p>四、4P理论: Price、Product、Place、Promotion（价格、产品、渠道、推广）。</p><ul><li>这4P理论有人认为有顺序，有人认为没有，老王倾向于认为有顺序，<strong>第一是Price，第二是Product，第三是Place， 第四是Promotion。为什么认为Price先于 Product？总的来说在规模化生产的行业里需求比供给重要，定价影响需求，而产品是供给</strong>。</li></ul><p>五、互联网时代的4P理论</p><ul><li>4P理论一方面是我们做商业模式设计的框架，另一方面是定义产业链的利益分配的。因此今天的4P理论仍然是Powerful的，但<strong>今天最厉害的一些商业模式是将4P中的某一个挤压为0进而获得强大的优势，然后在另一个P里赚钱，而互联网的存在大幅地提升了这种可能性</strong>。比如淘宝通过 Promotion和Place二合一的方式将Place收费变为0而收Promotion的钱。</li></ul></blockquote><h2 id="strategy-for-operation">Strategy for Operation</h2><p>分层经营和分类经营。</p><blockquote><p>一、分层经营</p><ul><li>没有一个产品可以满足其所在领域的所有需求，也没有一个经营分层可以解决所有需求， 不同的经营分层的差别是很大的，如果你不做经营分层而同行做了，这会导致你在对手的分层里没有竞争力，而分层也是非常难的。</li><li>分层经营的挑战在认知和组织层面都很大。比如团购这个生意如果公司觉得用户少了要搞用户，团队最简单的办法是搞头部商家，因为这些商家对用户的吸引力最强，如果觉得商家数量少了团队就会搞尾部商家，因为这些商家数量多，偏偏腰部商家被忽略了。<strong>分层经营之所以难不光是经营逻辑，也考核公司的组织能力，如果只用一个KPI去考核就会导致偏差</strong>。</li><li>典型的是麦当劳的优惠券，这个优惠券易用性不高，需要各种组合拼在一起能省几块钱或获得一个礼物，这其实是麦当劳扩大用户群的分层经营方法。<strong>互联网有一个理论是为消费者创造最好的消费体验，而麦当劳优惠券使用体验就很麻烦，这是因为这种使用体验匹配了价格敏感而时间成本低的用户分层；如果不做优惠券的话就让出了经营分层，是一种错误的经营方法；很多互联网人追求极致用户体验是因为产品复制成本为0且用户群足够大，而在有些行业里那些不好的体验有时候是产品设计的一部分</strong>。</li><li>头部商家议价能力强，也会提很多定制化需求，定制化需求是个无底洞，因此只做头部商家的软件公司很难赚钱。<strong>中国的 to B 软件发展得比较慢的原因是中国现在的企业分布是头部很大尾部很多，但腰部企业少，这对于企业软件厂商来说很难找到合适的客户群去做产品化</strong>。</li></ul><p>二、分类经营</p><ul><li><strong>如果我们对中国的互联网行业只砍一刀做分类，那么可以把公司分成供给和履约在线上的和供给和履约在线下的。 供给和履约在线下的可以分成以SKU为核心的生意和以Location为中心的生意</strong>。</li><li>线上是根据信息的可见度分成A1(微信、WhatsApp、Line)、A2 (Facebook)、A3(Twitter、微博、抖音、快手、Ins)、A4(今日头条、Google、百度、 腾讯视频)四个类别。微信里互发消息，有没有特定的好友，别人是看不到的；Facebook 里的好友别人是看得到的；Twitter发一条消息，所有人都能看到，但只有关注的人才会优先看到；而Google和今日头条里的信息所有人都能看到。如果一个产品集成了不同信息可见度的功能的话，消费者的区分难度是很大的。用最简化的方法描述他们的差异在于<strong>A1A2主要靠用心，A3A4主要靠算法</strong>，腾讯长期靠人脑而不是靠机器导致他们在机器学习上的算法不够强，尤其是把搜索业务卖给搜狗之后，但不是他们算法不行，而是他们应用算法的能力不够强。</li></ul></blockquote><h2 id="需求needs">需求（Needs）</h2><p>Needs是指用户原始的动机成因，Requirement是根据Needs产生的对产品的设计要求，Demand是产品生产出来后市场上的需求量，常和供给量一起讨论。我们讨论的需求是Needs。</p><p>需求具有不可满足性，永恒性和变化性的特点，如何来识别需求，如何识别具体的微观的需求？</p><blockquote><p>一、需求(Needs)的不可满足性</p><ul><li><strong>在人类的需求(Needs)中，能满足的需求(Needs)远远少于不能满足的需求(Needs)</strong>：如果你认识到了大部分需求(Needs)不可能被满足，你就可以坦然面对这一点了，这是一个非常Powerful的认知。</li><li><strong>在自然科学框架内能解决的需求(Needs)里，ROI正的需求(Needs)远远少于ROI负的需求 (Needs)</strong>。</li><li><strong>可支持一个团队规模化运作的需求(Needs)远远少于不可支持一个团队规模化运作的需求 (Needs)</strong>：满足需求(Needs)的ROI不是正的就可以，还要达到一定体量。 即便有需求(Needs)支持一个可规模化的团队，也要考虑它是否支持一个公司有竞争力地生存。</li><li>所以我们在任何一个时间点看这个社会上存在的靠谱的大商业机会，我们默认是没有的， 全球有这么多的人口这么多的优秀人才，如果有非常好的机会大家为什么不做呢?任何一 个大的需求(Needs)，在任何一个时间点，默认是没有机会的，认识到了这一点就会对很多事情有很强的批判精神，也可能会导致你错过机会。但真正有效的大需求是非常稀缺的。</li></ul><p>二、需求(Needs)的永恒性和变化性</p><ul><li>我们看到的需求固然是需求，但这个需求的变化是由很多根本性的要素驱动的。有些需求可能没变化，但由于科技等因素的变化导致实现需求的可能性发生了变化。还有些需求是因为社会环境、财富水平、人类认知等方面的原因，导致需求被放大了，在人类的层面需求存在就存在、不存在就不存在，但需求的强弱、广泛度、可实现性是受很多因素影响的。</li><li><strong>只有抓住重大关键的需求的成因，才能知道什么是ROI更高的需求，所以我们时时刻刻都要去评估需求的普遍程度、需求强度、实现需求的ROI</strong>。</li><li>所有伟大的需求都有两个很重要的特征，一个是人们会说这是一个伟大的需求但不可能实现，另一个是人们会说没有这个需求，他还会问你第三个问题为什么是现在，之前为什么没人做或没做成。就像之前讲的，所有伟大的需求一定会被前人在错误的时间用错误的方式尝试过，如果没有，那这就不是个伟大的需求。</li></ul><p>三、如何识别需求(Needs)</p><ul><li>一是怎么识别它，二是怎么来看待这件事。我们在做产品的时候，为什么当前是有的时间窗是可满足的，原因常常是因为经济社会等原因导致用户需求(Needs)变迁，或者是因为科技和基建的原因导致原来不可实现的需求可实现了，这两个结合在一起形成了需求的突破口，你要匹配这个突破口做一款产品，所以产品里的很多取舍一定要洞察突破的原因来做匹配。</li></ul><p>四、微观层面的需求(Needs)</p><ul><li>刚才说的需求是开创一个行业的大需求，现在说具体的微观的需求。识别微观的需求也很难，是因为我们很难直接看到需求的真面目。</li><li>很多时候需求只能猜，猜的命中率就很重要了，一个猜的方法是通过设置产品功能选项让客户选择选择来实现对需求的识别。</li><li>客户和你说产品缺什么功能是一个很普遍的情况，但你真的做出了这个产品客户也不一定就会用的，客户这么说只是因为你问了他不得不回答，可能只是因为他不回答的话可能显得自己很傻，他可能只是不是你的目标客户而已。客户可能有很多潜在的真实回答，比如产品太难用了他未必会直接说出来，说出来会让你难堪或者显得他自己傻。<strong>在产品早期的时候去问不用这个产品的人为什么不用很可能是一个无效的方法，真正有效的方法是问那些用了产品的人，这些人心里是有一定认可度的，且在使用的过程中遇到了问题</strong>。在我们讨论需求(Needs)的时候，有很多的误区需要去识别，很多人会提解决方案，因为解决方案不是需求本身。</li></ul></blockquote><h2 id="供需关系demand-and-supply">供需关系(Demand and Supply)</h2><p>供需关系的思考角度。</p><blockquote><p>一、供需关系的重要性</p><ul><li>如果是供过于求，需求很重要，需求方也知道自己很重要，需求方就很难伺候，团队就有很大的动力去搞供给方，因为供给方更迫切，所以团队在和供给方打交道的时候就如沐春风，而和需求方打交道的时候就很难受，所以团队就会有逃避的动力，大家就会装作不好搞的那一方不重要。</li><li><strong>人们很容易认为花时间多的事情就是重要的事情，而事实上不一定。 我们只有识别那些重要的事，把时间花在最重要的事上，才能提高ROI，这一定是供需里更稀缺的那一方</strong>。</li><li>更可怕的是把供需搞反了，后果会很严重。最近人人车把供需关系就搞反了，人人车的团 队很懂消费者心理，所以对需求端做了很多设计，用户体验很好，但二手车行业是一个供 不应求的行业，用户体验好但如果没有车就没用，这里瓜子二手车就和人人车展现出差异 来了，瓜子二手车的很多经营就是面向卖方的。</li></ul><p>二、空间因素</p><ul><li>一个行业的供需状态受空间的影响。举个在线婚恋市场的例子，从中国当前的男女比例来看是男性供过于求，分层来看，清华也是男性供过于求，但所有大学生里女生数量比男生多，整个中国的男女比是107:100，但农村里男女比例更悬殊，因为女性在城市里生存更容易，而在城市里尤其大城市里适龄单身男女数量上是女多于男。这就影响到很多东西， 比如你做相亲网站定位城市白领和定位农村市场时，打广告推广应该面向哪一方，哪一方更容易成为付费会员，可能完全相反。</li></ul><p>三、时间因素</p><ul><li>不同行业供需变化受时间影响的频率不同，比如打车行业是供需变化在时间上比较快的，零售这个行业从时间上来说供需变化通常是不快的。</li><li>如果大家有一天自己经营公司就会面临某一项组织能力在公司内是建设还是不建设的问题，比如要不要建设技术团队、产品团队、商分团队等，这都是很重要的组织战略决策， 这就取决于你所处行业的特征。</li></ul><p>四、分层因素</p><ul><li><strong>分层和分类通常在不同行业的分法是不一样的，回到STP划分的格子，每个格子里的供需状况都是不一样的</strong>。</li><li>高端的供需弹性大，低端供需弹性小(刚需)，高端客户有钱，对于买错一个东西试错成本低，客户可以买各种各样的东西。比如Elon Musk打中了有钱人的这样一个心理：我不仅有钱，还关注环保问题。虽然续航里程不一定够，反正这也不是我家里唯一车辆。</li></ul><p>五、非市场要素</p><ul><li>事实上无论大家多么强调市场要素，非市场要素都是非常多的，即便在美国。</li></ul><p>六、线上线下</p><ul><li>线上线下也影响供需。一个市场线下供不应求， 可能在线上却供大于求的。互联网对线上线下的供需是有非常大影响的。</li><li><strong>路径依赖是商业世界的牛顿第一定律</strong>。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;这几天晚上，又把王慧文的清华产品课文稿看了遍，每读必要收获，这里做些摘要。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;产品经理是一个需要终身学习的职业，如果固化自己的知识体系和发展方向，是不太可能有太高成就。产品经理的核心能力是关于方法论，如果能掌握正确的方法论，就具备了跨领域的通用性。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;产品经理是一个需要终身学习的职业，想学一门专业的技术，一段时间后就只用好这门技术，或者专业能力只局限在一个领域，就不容易做好产品经理。&lt;strong&gt;产品经理是一个跨领域的专业，需要解决很多新的问题，如果固化自己的知识体系和发展方向，就不太可能在产品经理这个领域有太高的成就。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;产品经理这个岗位是强专用性和强通用性同时存在的&lt;/strong&gt;。&lt;strong&gt;专用性上&lt;/strong&gt;，例如电商产品经理和游戏产品经理的专业差别很大，美团阿里腾讯都有产品经理，但他们的专用技能差别很大。 在一个领域很成功的产品经理换一个领域，他的工作方法可能就不灵了。&lt;strong&gt;通用性&lt;/strong&gt;也是很强的，例如Neil做肥皂和做国防部长，这两件事差别很大，但如果产品经理能掌握其中最关键的通用能力，就能快速上手其他的行业。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;产品经理的核心能力是关于方法论的，正确的思考方法、正确的沟通方法、正确的工作方法、正确的认知方法、正确的学习方法，如果能掌握正确的方法论，那就具有了跨领域的通用性。&lt;/strong&gt;这也是Pichai(作为一个 冶金专业的人)和Google(作为一家搜索引擎为主的公司)能做好Chrome的意义，这说明他们的通用性能力很强。&lt;/p&gt;
&lt;p&gt;产品经理是CEO的学前班，Pichai和Neil都不是专业出身最后成为CEO，但前提是你要有做创业产品经理的心态和思维。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;战略&quot;&gt;战略&lt;/h2&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Data Driven 101</title>
    <link href="http://blog.zhengdong.me/2021/09/04/data-driven-101/"/>
    <id>http://blog.zhengdong.me/2021/09/04/data-driven-101/</id>
    <published>2021-09-04T12:08:45.000Z</published>
    <updated>2021-09-04T12:17:34.241Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近主力写作+笔记工具从 <a href="https://ulysses.app">Ulysses</a> 往 <a href="https://www.craft.do">Craft</a> 切换，整理文章，发现篇18年为团队产品升级写的“软文”，读起来觉得不过时，删减掉“软”的内容旧文重发。</p></blockquote><p>大佬们在说，互联网下半场了。</p><p>各种文章也告诉我们，人口红利已经结束了，流量红利也褪去了，资本红利更是萎缩的不要不要的。</p><p>做产品的拉不到用户紧张不？做运营的留不住用户焦虑不？</p><p>很多人在谈数据驱动，仿佛抓住它，就可以解决业务过程出现的各种问题。</p><h2 id="boss-driven-data-analysis">Boss-Driven Data Analysis</h2><p>数据驱动离不开数据，离不开对企业/产品关键指标的跟踪。</p><p>市面上有很多分析产品，提供从数据采集到展示的的标准统计服务，比如国内的百度统计、友盟等，接入后，可以看到产品的用户、日活、渠道等概要情况。我们团队几年前也开发过类似的一系列产品，公司内部很多业务线都在使用。</p><p>"很多同事，每天早上会登陆系统看下，日活稳定、新增在变大，很好。"</p><p>"当然也有可能，啊！日活怎么掉这么多，呃，不应该呀，奥，今天加班是周六，那正常 。。。"</p><p>很多业务都会有年度关键目标，比如用户增长到X亿，日活到X千万，营收到XX亿。于是做个报表，把这些关键数据都放在里面，实时更新，领导可以一目了然看到整体目标的完成情况，大家也努力工作，看着目标一天天接近。</p><p>这样有问题么？</p><p>看到用户一天增长了 10 万，除了感到欣喜，还能做什么？</p><p>看到总用户数突破 1 亿，除了感到好长脸，还能做什么？</p><p>除非产品出了大问题，否则用户总是在增长的，总用户数总是一条蓬勃向上的曲线。</p><p>数据驱动，数据是基础，但关键在驱动。看到一个指标，如果不能回答，依靠这个指标，能怎么行动，那还不如索性不要太过关注这个指标，要能思考怎么去行动，这样才能持续优化。</p><p>比如看到 PV 是 1000，到底来源于 1000 个用户，还是 10 个访问了 100 次的用户？所以，这个指标无法驱动行动。</p><h2 id="segmentation-cohort-ab-testing">Segmentation, Cohort, A/B testing</h2><p>那如何找到可付诸行动的指标？</p><h3 id="细分">细分</h3><p>细分，就是通过对用户行为的特征筛选，找到有共同特征的人。比如在杭州滨江区的用户、使用 iPhone 手机的用户、使用 4G 网络听歌的用户。</p><p>以运营内容网站举例，通过一系列技术对访客进行细分，比较不同细分特征用户的行为差异、付费转化率差异，如发现使用华为手机的用户的付费转化情况明显高于小米手机用户，那就可以进一步行动去调查背后的原因，再将发现的成功要素复制到其他细分用户中，扩大整体付费转化率。</p><p>当然，也有可能被残酷的现实击倒，付费过程在小米系统存在偶现 bug，影响付费流程。但这也是有价值的发现，没有细分维度的数据对比，问题可能会隐藏非常久。</p><h3 id="分群">分群</h3><p>细分是通过行为特征对用户进行筛选，而分群则是通过用户属性特征对用户的筛选，比如男性用户、比如 6.18 大促带过来的新增用户、比如支付能力强的用户等。</p><p>有了分群，可以针对不同的用户群，进行产品的功能使用比较，基于目标用户需求来优化产品设计，比如通过比较新、老用户的产品留存、使用粘性情况，来对用户进行精细化运营。</p><p>以运营电商网站举例，通过比较不同推广渠道带过来的用户消费情况，可以进行合作渠道筛选和推广策略优化，甚至可以发现某些渠道刷的都是僵尸用户。</p><h3 id="ab-测试">A/B 测试</h3><p>有了分群和细分，就可以对不同群体，在同一时间段展示不同的功能，比如按钮的不同位置，链接的不同颜色等，来研究哪些功能比较吸引用户。也可以在目标小用户群体中验证产品的一些新特征，而对其他用户不造成困扰。</p><p>甚至还可以搞恶作剧。</p><p>曾经 TechCrunch 经常乱报 Facebook 的新闻，Facebook 决定反击，09 年的时候上线了个功能，"Fax Photo" （用户可以传真 Facebook 上面的照片），并设定该功能可见范围（用户群）为 TechCrunch 办公网络。TechCrunch 的一位编辑看到后马上发了篇文章，谈使用 "Fax Photo" 的感受，大肆抒发对于此功能鸡肋性的吐槽，这年头还开发这种过时功能。完全没想到，<a href="https://techcrunch.com/2009/09/10/facebook-now-lets-you-fax-your-photos-i-have-no-idea-why-anyone-would-want-to-do-this/">这个功能只有他们能看得到</a>。</p><h2 id="用户行为分析">用户行为分析</h2><p>上面说了这么多，想必大家也能理解为啥仅仅看概要统计数据对业务价值有限，也能想到对用户不同行为特征、不同属性分布进行比对分析对业务决策的重要性。</p><p>那么，有什么工具可以辅助大家来做这些事情呢？</p><p>XXXX 是一款基于用户行为的实时数据分析&amp;A/B测试产品，提供数据从采集、建模、存储到展现的端到端解决方案，只需要在产品中接入 SDK 就可以实时进行用户洞察，优化产品设计、提升用户粘性、掌握用户动态。</p><p>... ...</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;最近主力写作+笔记工具从 &lt;a href=&quot;https://ulysses.app&quot;&gt;Ulysses&lt;/a&gt; 往 &lt;a href=&quot;https://www.craft.do&quot;&gt;Craft&lt;/a&gt; 切换，整理文章，发现篇18年为团队产品升级写的“软文”，读起来觉得不过时，删减掉“软”的内容旧文重发。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大佬们在说，互联网下半场了。&lt;/p&gt;
&lt;p&gt;各种文章也告诉我们，人口红利已经结束了，流量红利也褪去了，资本红利更是萎缩的不要不要的。&lt;/p&gt;
&lt;p&gt;做产品的拉不到用户紧张不？做运营的留不住用户焦虑不？&lt;/p&gt;
&lt;p&gt;很多人在谈数据驱动，仿佛抓住它，就可以解决业务过程出现的各种问题。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>内容型/报表型数据产品的基础评价系统</title>
    <link href="http://blog.zhengdong.me/2021/08/22/evaluation-system-for-report-based-data-product/"/>
    <id>http://blog.zhengdong.me/2021/08/22/evaluation-system-for-report-based-data-product/</id>
    <published>2021-08-22T13:11:35.000Z</published>
    <updated>2021-08-22T13:20:07.409Z</updated>
    
    <content type="html"><![CDATA[<p>可以作为数据产品的baseline要求。</p><p><strong>一、价值部分</strong></p><ul><li>优：产品的使用<strong>价值</strong>如何。衡量维度：<ul><li>访问：人数、频次、职级分布等。</li><li>传播：收藏、分享等。</li><li>内容建设：内容完善度。</li><li>其他：用户反馈/调研，...</li></ul></li><li>省：产品运行所消耗的<strong>成本</strong>。衡量维度：<ul><li>数据计算成本。</li><li>数据存储成本。</li><li>系统资源成本。</li><li>其他：人力运维成本，...</li></ul></li></ul><p><strong>二、质量部分</strong></p><ul><li>稳：产品是否能<strong>稳定</strong>提供服务。衡量维度：<ul><li>离线数据延迟和异常情况。</li><li>实时数据延迟和异常情况。</li><li>查询报错情况。</li><li>其他稳定性问题。</li></ul></li><li>准：产品提供的数据是否<strong>准确</strong>。衡量维度：<ul><li>数据走查/巡检错误数量。</li><li>线上问题数量。</li><li>用户主动反馈问题数量。</li><li>其他数据准确性问题。</li></ul></li><li>快：产品的<strong>响应</strong>是否足够快。衡量维度：<ul><li>最大/小响应时长，平均响应时长情况。</li><li>慢请求次数及占比。</li><li>其他查询响应问题。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;可以作为数据产品的baseline要求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、价值部分&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优：产品的使用&lt;strong&gt;价值&lt;/strong&gt;如何。衡量维度：
&lt;ul&gt;
&lt;li&gt;访问：人数、频次、职级分布等。&lt;/li&gt;
&lt;li&gt;传播：收藏、分享等。&lt;/li&gt;
&lt;li&gt;内容建设：内容完善度。&lt;/li&gt;
&lt;li&gt;其他：用户反馈/调研，...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;省：产品运行所消耗的&lt;strong&gt;成本&lt;/strong&gt;。衡量维度：
&lt;ul&gt;
&lt;li&gt;数据计算成本。&lt;/li&gt;
&lt;li&gt;数据存储成本。&lt;/li&gt;
&lt;li&gt;系统资源成本。&lt;/li&gt;
&lt;li&gt;其他：人力运维成本，...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二、质量部分&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;稳：产品是否能&lt;strong&gt;稳定&lt;/strong&gt;提供服务。衡量维度：
&lt;ul&gt;
&lt;li&gt;离线数据延迟和异常情况。&lt;/li&gt;
&lt;li&gt;实时数据延迟和异常情况。&lt;/li&gt;
&lt;li&gt;查询报错情况。&lt;/li&gt;
&lt;li&gt;其他稳定性问题。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;准：产品提供的数据是否&lt;strong&gt;准确&lt;/strong&gt;。衡量维度：
&lt;ul&gt;
&lt;li&gt;数据走查/巡检错误数量。&lt;/li&gt;
&lt;li&gt;线上问题数量。&lt;/li&gt;
&lt;li&gt;用户主动反馈问题数量。&lt;/li&gt;
&lt;li&gt;其他数据准确性问题。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;快：产品的&lt;strong&gt;响应&lt;/strong&gt;是否足够快。衡量维度：
&lt;ul&gt;
&lt;li&gt;最大/小响应时长，平均响应时长情况。&lt;/li&gt;
&lt;li&gt;慢请求次数及占比。&lt;/li&gt;
&lt;li&gt;其他查询响应问题。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>数据 To B 商业化的一些心得</title>
    <link href="http://blog.zhengdong.me/2021/06/26/thoughts-on-tob-data-commercialization/"/>
    <id>http://blog.zhengdong.me/2021/06/26/thoughts-on-tob-data-commercialization/</id>
    <published>2021-06-26T14:08:08.000Z</published>
    <updated>2021-06-26T14:14:06.458Z</updated>
    
    <content type="html"><![CDATA[<p>从产品、商业策略和组织视角谈谈自己对数据 To B 商业化的一些心得。</p><h2 id="产品视角">产品视角</h2><p><strong>如何做一个好的数据产品？</strong></p><ol type="1"><li><p>分清客户和用户。</p><p>客户是产品的购买者，用户是产品的实际使用者。</p><p>大部分情况下，客户和用户不是一群人，甚至在企业里往往层级相差很多，对产品有不同诉求很正常。面临不同诉求，要记住一条准则：产品的价值是帮助客户实现其业务价值。</p></li><li><p>分层服务“阅览者”和“编辑者”。</p><p>“阅览者”消费产品的内容，”编辑者“生产产品的内容，产品不仅要让消费者很舒服，也要帮助生产者提效降本。</p></li><li><p>平衡好“功能强大”和“简单上手”的矛盾。</p><p>能服务好超级用户是产品在竞争中获得优势的核心能力，但不能自high，将产品的上手难度和产品的能力挂钩。</p><p>真正做到初级用户很容易上手，但随着使用的深入，不断发掘更多更深入的功能，才是产品的能力体现。</p></li><li><p>兼顾产品的前台功能和运维治理能力建设。</p><p>不光要做被用户看得到的功能，也要关注产品的运维保障、用户使用监控、资源成本治理等能力建设，做到产品全生命周期的管理和服务。</p></li></ol><p><strong>如何做好B端产品经理？</strong></p><ol type="1"><li><p>和企业业务负责人建立深入连接。</p><p>能和企业业务负责人建立顺畅且持续沟通的关系，了解业务方向，才能对该做什么心中有数。</p></li><li><p>追寻需求业务价值。</p><p>能从需求中洞察业务价值，通过对业务价值的判断而不是产品的实现难易来定优先级。</p></li><li><p>做很懂业务的通才。</p><p>技术产品经理要懂技术，数据产品经理要懂服务的业务或行业。</p></li></ol><p><strong>数据智能在产品上落地有哪些方向？</strong></p><ol type="1"><li><p>数据洞察（Insights）</p><p>1）诊断归因，包括指标拆解、归因，业务流程诊断、归因等；2）智能交互，包括数据智能解读，问答式交互等。</p></li><li><p>数据预测（Prediction）</p><p>1）机会发现；2）趋势预测；3）异常检测。</p></li></ol><p><strong>数据产品特别是分析型数据产品 SaaS 化的几个方向？</strong></p><ol type="1"><li>对接线上SaaS产品（营销、客服、财务等SaaS服务），自动生成数据看板。</li><li>场景化分析模版市场，打造行业分析经验分享和交流平台。</li><li>一站式数仓技术服务，数据接入、生产、应用和管理SaaS化。</li><li>数据共享和交换平台，数据作为资产能在保障数据安全的情况下共享或交易。</li></ol><p><strong>最后</strong></p><ul><li>2B 需要稳而慢，稳指对产品的质量要求非常高，慢指产品发布要做到慢节奏，且重视向后兼容。</li></ul><h2 id="商业策略视角">商业策略视角</h2><p><strong>选择什么样的客户？</strong></p><ol type="1"><li>选择增长行业客户：客户增长，产品才能体现更大价值，才能赢得口碑。</li><li>聚焦行业头部客户：成功落地头部企业，才能更好在行业内做复制。</li></ol><p><strong>如何做产品定价？</strong></p><ol type="1"><li>定价要与你的潜在客户数、客户分布相匹配。</li><li>定价既要能够保证合理的销售速度，又要有足够的利润流向销售渠道。</li></ol><p><strong>如何设计产品策略？</strong></p><ol type="1"><li>标准产品和解决方案并重：标准产品打长尾，解决方案打头部。</li><li>做解决方案，要敬畏客户，认真做功课：知己知彼，研究客户及其竞争对手，针对性给出解决方案。</li><li>解决方案要尽量产品化：聚焦行业，定制需求做场景化抽象，才能规模化复制。</li><li>对外版本更新不求快，重视产品质量和前后一致性。</li></ol><p><strong>做客户服务要关注什么？</strong></p><ol type="1"><li>基于客户分层的差异化运营体系，有中长尾客户，才有未来。</li><li>关注客户钱包深度，持续挖掘商机。</li><li>数字化客户全生命周期应用，持续优化。</li><li>后方出台尽可能后置，可安排在在临门一脚时，或产品交付回访时。</li></ol><h2 id="组织视角">组织视角</h2><p><strong>商业化团队有哪些角色？</strong></p><p>市场、销售、产品，三足鼎立。不同于2C，销售和市场拥有巨大的话语权。</p><p><strong>商业化团队的岗位如何设定？</strong></p><ol type="1"><li><p>售前阶段，</p><p>销售（客户经理）负责商机跟进，维持客户关系和合同洽谈。</p><p>售前（解决方案架构师），站在客户视角，从产品的角度为客户提供解决方案建议。</p><p>ToB市场，负责网站及外宣材料、线上推广（SEM）、活动/会议组织、社区运营、客户成功案例收集、竞品调查等。</p></li><li><p>售后阶段，</p><p>实施工程师、交付经理，为产品交付负责。</p><p>技术支持/客户成功，为客户满意度负责。</p></li></ol><p><strong>最后</strong></p><ul><li>To B需要既懂技术又懂业务的技术商人，为业务规模和P&amp;L负责。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;从产品、商业策略和组织视角谈谈自己对数据 To B 商业化的一些心得。&lt;/p&gt;
&lt;h2 id=&quot;产品视角&quot;&gt;产品视角&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;如何做一个好的数据产品？&lt;/strong&gt;&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;分清客户和用户。&lt;/p&gt;
&lt;p&gt;客户是产品的购买者，用户是产品的实际使用者。&lt;/p&gt;
&lt;p&gt;大部分情况下，客户和用户不是一群人，甚至在企业里往往层级相差很多，对产品有不同诉求很正常。面临不同诉求，要记住一条准则：产品的价值是帮助客户实现其业务价值。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分层服务“阅览者”和“编辑者”。&lt;/p&gt;
&lt;p&gt;“阅览者”消费产品的内容，”编辑者“生产产品的内容，产品不仅要让消费者很舒服，也要帮助生产者提效降本。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;平衡好“功能强大”和“简单上手”的矛盾。&lt;/p&gt;
&lt;p&gt;能服务好超级用户是产品在竞争中获得优势的核心能力，但不能自high，将产品的上手难度和产品的能力挂钩。&lt;/p&gt;
&lt;p&gt;真正做到初级用户很容易上手，但随着使用的深入，不断发掘更多更深入的功能，才是产品的能力体现。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;兼顾产品的前台功能和运维治理能力建设。&lt;/p&gt;
&lt;p&gt;不光要做被用户看得到的功能，也要关注产品的运维保障、用户使用监控、资源成本治理等能力建设，做到产品全生命周期的管理和服务。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;如何做好B端产品经理？&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Psychological Safety</title>
    <link href="http://blog.zhengdong.me/2021/05/09/psychological-safety-google-perfect-team/"/>
    <id>http://blog.zhengdong.me/2021/05/09/psychological-safety-google-perfect-team/</id>
    <published>2021-05-09T12:43:03.000Z</published>
    <updated>2021-05-10T15:49:16.832Z</updated>
    
    <content type="html"><![CDATA[<p>上周看的一篇文章了解到一个概念，Psychological Safety，大致可翻译成「心理安全」。</p><p>文章标题是 <em>What Google Learned From Its Quest to Build the Perfect Team</em>，发表在 <a href="https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html">The New York Times Magazine</a>，具体内容<a href="https://centre.upeace.org/wp-content/uploads/2020/09/7.1-what-google-learnt.pdf">这里</a>可以找到，主要是 Google 内部一个研究高效团队有哪些共同点的项目（Project Aristotle）得出的结论。</p><p>针对如何打造一个好团队，研究者分析了很多数据，但无法找到某种统一的决定性模式。无论团队成员的性格类型、技能和背景如何，大家生活上是好朋友还是公私分明私下无交集，是强管理还是扁平结构弱管理等，都存在成功的团队。</p><p>文中的一个例子我印象非常深刻：</p><blockquote><p><strong>Imagine you have been invited to join one of two groups.</strong></p><p><strong>Team A</strong> is composed of people who are all exceptionally smart and successful. When you watch a video of this group working, you see professionals who wait until a topic arises in which they are expert, and then they speak at length, explaining what the group ought to do. When someone makes a side comment, the speaker stops, reminds everyone of the agenda and pushes the meeting back on track. This team is efficient. There is no idle chitchat or long debates. The meeting ends as scheduled and disbands so everyone can get back to their desks.</p><p><strong>Team B</strong> is different. It’s evenly divided between successful executives and middle managers with few professional accomplishments. Teammates jump in and out of discussions. People interject and complete one another’s thoughts. When a team member abruptly changes the topic, the rest of the group follows him off the agenda. At the end of the meeting, the meeting doesn’t actually end: Everyone sits around to gossip and talk about their lives.</p><p><strong>Which group would you rather join?</strong></p></blockquote><p>我想很多人会像我一样，第一反应，“当然 Team A 呀，高效、聚焦、能看出很强的执行力”。但按照文章的结论，长远看，Team B 可能会胜过 Team A。</p><p>因为研究者最终总结出对成为高效团队起关键性作用的是一种 <em>group norms</em> ，所有好团队都具备如下两个行为模式。</p><blockquote><p><em>Norms are the traditions, behavioral standards and unwritten rules that govern how we function when we gather</em></p></blockquote><ol type="1"><li><p><strong>Conversational turn-taking</strong>: On the good teams, members spoke in roughly the same proportion, a phenomenon the researchers referred to as ʻʻequality in distribution of conversational turn-taking.’’</p></li><li><p><strong>Empathy</strong>: The good teams all had high ʻʻaverage social sensitivity’’ - a fancy way of saying they were skilled at intuiting how others felt based on their tone of voice, their expressions and other nonverbal cues.</p></li></ol><p>这两种行为模式对构建心理安全的环境很重要。</p><blockquote><p>The behaviors that create psychological safety — conversational turn‐taking and empathy — are part of the same unwritten rules we often turn to, as individuals, when we need to establish a bond. And those human bonds matter as much at work as anywhere else. In fact, they sometimes matter more.</p></blockquote><hr /><p>文章的结论主要是基于 Google 内部的情况得出的，不一定适合所有企业，但当企业面临组织问题时，不妨作为一个思考视角。</p><p>比如重视战功，能推动领导者快速成长，但可能会导致一言堂文化，阻碍观点的百花齐放。末位淘汰，能激发和提升员工的执行力，但当发展速度降低，外部机会变少时，可能会出现大量内耗，何谈同理心文化。</p><p>每家企业都有自己的路径依赖，是坚持以往，相信苦难是暂时的，还是“刷新”自我，探寻另一种发展路径。我觉得要成为一家基业长青的公司，后者是一种核心能力。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;上周看的一篇文章了解到一个概念，Psychological Safety，大致可翻译成「心理安全」。&lt;/p&gt;
&lt;p&gt;文章标题是 &lt;em&gt;What Google Learned From Its Quest to Build the Perfect Team&lt;/em&gt;，发表在 &lt;a href=&quot;https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html&quot;&gt;The New York Times Magazine&lt;/a&gt;，具体内容&lt;a href=&quot;https://centre.upeace.org/wp-content/uploads/2020/09/7.1-what-google-learnt.pdf&quot;&gt;这里&lt;/a&gt;可以找到，主要是 Google 内部一个研究高效团队有哪些共同点的项目（Project Aristotle）得出的结论。&lt;/p&gt;
&lt;p&gt;针对如何打造一个好团队，研究者分析了很多数据，但无法找到某种统一的决定性模式。无论团队成员的性格类型、技能和背景如何，大家生活上是好朋友还是公私分明私下无交集，是强管理还是扁平结构弱管理等，都存在成功的团队。&lt;/p&gt;
&lt;p&gt;文中的一个例子我印象非常深刻：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Imagine you have been invited to join one of two groups.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Team A&lt;/strong&gt; is composed of people who are all exceptionally smart and successful. When you watch a video of this group working, you see professionals who wait until a topic arises in which they are expert, and then they speak at length, explaining what the group ought to do. When someone makes a side comment, the speaker stops, reminds everyone of the agenda and pushes the meeting back on track. This team is efficient. There is no idle chitchat or long debates. The meeting ends as scheduled and disbands so everyone can get back to their desks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Team B&lt;/strong&gt; is different. It’s evenly divided between successful executives and middle managers with few professional accomplishments. Teammates jump in and out of discussions. People interject and complete one another’s thoughts. When a team member abruptly changes the topic, the rest of the group follows him off the agenda. At the end of the meeting, the meeting doesn’t actually end: Everyone sits around to gossip and talk about their lives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Which group would you rather join?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>读情境领导者和钝感力</title>
    <link href="http://blog.zhengdong.me/2021/04/11/situational-leader-and-insensitivity-power/"/>
    <id>http://blog.zhengdong.me/2021/04/11/situational-leader-and-insensitivity-power/</id>
    <published>2021-04-11T05:31:20.000Z</published>
    <updated>2021-05-12T16:13:21.519Z</updated>
    
    <content type="html"><![CDATA[<p>最近看书，有两本印象不错。</p><p>第一本是「<a href="https://book.douban.com/subject/1102987/">情境领导者</a>」，比较老的书，是一套帮助领导者提高领导行为有效性的模式：有效的领导风格需要和被领导者的准备度水平相匹配。</p><p>这方面知识很多管理类书都会提及，这本书给我带来的最大收获在于做了系统化拆解，可以说以前是基于内心认知来实践，通过这本书，变得更具象，更可被衡量。</p><p>首先是领导者风格的定义：1）领导者采用的<strong>工作行为</strong>的数量；2）领导者采用的<strong>关系行为</strong>的数量。</p><ul><li><strong>工作行为</strong>：是指领导者清楚的说明个人或组织的责任的程度。这种行为包括告诉人们做什么，如何做，什么时间做，在哪里做，以及由谁来做。</li><li><strong>关系行为</strong>：是指当管理对象超过一个人的时候，领导者进行双向或者多向沟通的程度。这种行为包括倾听、鼓励、协助、提供工作说明以及给予社交方面的支持等。</li></ul><p>基于这两类行为的定义，可以将领导风格划分四类：</p><ul><li>S1: 高工作，低关系：指令型 (<strong>telling</strong>)，提供明确的说明和密切的监管。</li><li>S2: 高工作，高关系：教练型 (<strong>selling</strong>)，解释你的决策并给予对方要求陈述的机会。</li><li>S3: 低工作，高关系：支持型 (<strong>participating</strong>)，交换意见并辅助被领导者制定决策。</li><li>S4: 低工作，低关系：授权型 (<strong>delegating</strong>)，将决策和执行的职责交给员工。</li></ul><p>接下来是对被领导者的准备度水平的定义：指被领导者完成某项特定的工作所表现出来的<strong>能力</strong>和<strong>意愿</strong>水平。</p><ul><li><strong>能力</strong>是指个人或组织在某一项特定的工作或活动中所表现出的知识、经验与技能。</li><li><strong>意愿</strong>是指个人或组织完成某一项特定的工作或活动而表现出的信心、承诺和动机。</li></ul><p>同样基于这两项，将被领导者准备度水平划分四类：</p><ul><li>R1: 没能力 &amp; 没意愿或不安</li><li>R2: 没能力 &amp; 有意愿或自信</li><li>R3: 有能力 &amp; 没意愿或不安</li><li>R4: 有能力 &amp; 有意愿并自信</li></ul><p>最后是领导风格和被领导者准备度水平的匹配关系，S和R一一对应（R1、R2 领导者主导，R3、R4 被领导者主导），见下图。</p><p><a><img src="/images/2021/the-situational-leader.png" width="560"></a></p><p>后来发现情境领导还有个2.0版本“<a href="https://wiki.mbalib.com/wiki/%E6%83%85%E5%A2%83%E9%A2%86%E5%AF%BC%E2%85%A1">情境领导II</a>”，对被领导者状态划分做了调整，改变点是从变化的角度来看员工工作意愿和工作能力的改变。</p><ul><li>D1: 低能力 &amp; 高意愿（热情的初学者）</li><li>D2: 中低能力 &amp; 低意愿（憧憬幻灭的学习者）</li><li>D3: 中高能力 &amp; 意愿不定（能力但谨慎的执行者）</li><li>D4: 高能力 &amp; 高意愿（独立自主的完成者）</li></ul><p>同样，和领导风格的匹配关系还是一一对应。情境领导两个版本区别点就在于，R1、R2 和 D1、D2 调换了顺序。</p><p>第二本书是渡边淳一 的「<a href="https://book.douban.com/subject/2119843/">钝感力</a>」，是本励志畅销书。整本书从人生/职场发展，人际关系，身体健康，男女关系等各方面，举各种例子来讲述一个道理：虽然钝感有时给人以迟钝、木讷的负面印象，钝感力却是我们赢得美好生活的手段和智慧。</p><p>整本读起来很容易，读的过程也再三告诉自己，不要较真，这不是本理论或者教科书，而是作者讲述自己人生哲学的小册子。</p><p>我的收获：感官上的钝感和敏感，和人格特质关系很大，很多时候不好改变，所以“钝感力”更是在对失败、挑战、焦虑、诱惑等的应对上要钝感，这是可以被训练的。钝感力的最终表现是对不确定性的接纳和消化能力，也就是”<a href="https://book.douban.com/subject/25782902/">反脆弱</a>”的能力。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近看书，有两本印象不错。&lt;/p&gt;
&lt;p&gt;第一本是「&lt;a href=&quot;https://book.douban.com/subject/1102987/&quot;&gt;情境领导者&lt;/a&gt;」，比较老的书，是一套帮助领导者提高领导行为有效性的模式：有效的领导风格需要和被领导者的准备度水平相匹配。&lt;/p&gt;
&lt;p&gt;这方面知识很多管理类书都会提及，这本书给我带来的最大收获在于做了系统化拆解，可以说以前是基于内心认知来实践，通过这本书，变得更具象，更可被衡量。&lt;/p&gt;
&lt;p&gt;首先是领导者风格的定义：1）领导者采用的&lt;strong&gt;工作行为&lt;/strong&gt;的数量；2）领导者采用的&lt;strong&gt;关系行为&lt;/strong&gt;的数量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;工作行为&lt;/strong&gt;：是指领导者清楚的说明个人或组织的责任的程度。这种行为包括告诉人们做什么，如何做，什么时间做，在哪里做，以及由谁来做。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关系行为&lt;/strong&gt;：是指当管理对象超过一个人的时候，领导者进行双向或者多向沟通的程度。这种行为包括倾听、鼓励、协助、提供工作说明以及给予社交方面的支持等。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>对 DataOps 的一些理解</title>
    <link href="http://blog.zhengdong.me/2021/03/10/about-dataops/"/>
    <id>http://blog.zhengdong.me/2021/03/10/about-dataops/</id>
    <published>2021-03-10T03:50:11.000Z</published>
    <updated>2021-03-13T07:50:10.038Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了一些关于 DataOps 的书和文章，对自己的理解做个总结。</p><h2 id="dataops-要解决什么问题">DataOps 要解决什么问题？</h2><p>两个价值点，第一是<strong>提高数据生产到价值产出全链路的效率</strong>，第二是<strong>用数据来持续优化整个数据链路的可用性和价值</strong>。</p><h2 id="dataops-是什么">DataOps 是什么？</h2><p>下面是 Gartner 对 DataOps 的<a href="https://www.gartner.com/en/information-technology/glossary/dataops">定义</a>。</p><blockquote><p>DataOps is a collaborative data management practice focused on improving the communication, integration and automation of data flows between data managers and data consumers across an organization.</p></blockquote><p>这里包含三份信息：</p><ol type="1"><li>DataOps 是包括人，流程和技术的一组体系和实践，用来管理代码，工具，基础架构和数据本身，</li><li>它针对的是数据生产者和数据消费者间的整个数据流（价值链路），</li><li>它持续优化链路上参与方的协作，集成和自动化能力。</li></ol><p>接下来的描述，指出了 DataOps 理念的的三个支柱：</p><blockquote><p>The goal of DataOps is to deliver value faster by creating predictable delivery and change management of data, data models and related artifacts.</p></blockquote><p>敏捷，</p><blockquote><p>DataOps uses technology to automate the design, deployment and management of data delivery with appropriate levels of governance,</p></blockquote><p>自动化，</p><blockquote><p>and it uses metadata to improve the usability and value of data in a dynamic environment.</p></blockquote><p>和持续优化。</p><p>基于这些支柱，DataOps 构建和持续优化两个工作流。一个是 “<strong>The Value Pipeline</strong>”，覆盖数据接入，ETL、建模、可视化/报表整个流程，我认为可以抽象成“<strong>建好数据</strong>”。第二是 “<strong>The Innovation Pipeline</strong>”，流程包括从想法、到研发、再到生产验证，我认为可以抽象为“<strong>用好数据</strong>”。</p><p>DataOps 对“建好数据”流程进行全链路提效，以及通过数据反向优化进一步提高效率和质量。为“用好数据”流程提供高效的开发和试验工具，以及多环境支持（Sandbox或预发、测试环境），高效试验不影响线上。</p><h2 id="如何来落地-dataops">如何来落地 DataOps？</h2><p>从人、流程和技术的三方面来看。</p><p><strong>DataOps 的客户是谁？</strong></p><p>是整个数据团队，包括了产品经理，数据研发，工程开发，测试，运维，数据科学，数据分析师等人员。</p><p><strong>数据生产者到数据消费者的流程包括哪些环节？</strong></p><p>1）开发阶段，目标是持续集成；2）部署阶段，目标是持续部署；3）编排阶段，是解决工作流自动化和调度问题；4）测试阶段，建立监控和告警机制，目标是提升数据的质量。</p><p><strong>涉及到的数据技术有哪些？</strong></p><p>1）数据采集：采集和整合异构数据；2）数据存储：基于计算基础设施之上的数仓或数据湖；3）数据生产：数据开发、优化、测试等技术；4）数据管理：元数据管理和数据治理技术；5）数据分析：数据报表，可视化，数据科学工具等技术。</p><p>基于以上技术，在敏捷、自动化和持续优化的加持下，要建立四个能力：数据工程（处理和加工数据的能力），数据集成（多样、异构数据的整合能力），数据安全（端到端的数据安全和隐私管控能力）和数据质量（数据的一致性、准确性、及时性等数据质量保障能力）。</p><p>摘抄 <a href="https://datakitchen.io/the-dataops-cookbook/">The DataOps Cookbook</a> 书中的一些内容：</p><blockquote><p>The Seven Steps to Implement DataOps</p><ol type="1"><li>Add data and logical tests</li><li>Use a version control system</li><li>Branch and merge</li><li>Use multiple environments</li><li>Reuse and containerize</li><li>Parameter your processing</li><li>Working without fear or heroism</li></ol></blockquote><p>总结起来，就是将数据纳入测试，提供分支和多环境能力，自动化执行，且便于复用。</p><blockquote><p><a href="https://www.dataopsmanifesto.org">The DataOps Manifesto</a></p><ol type="1"><li>Continuously satisfy your customer</li><li>Value working analytics</li><li>Embrace change</li><li>It’s a team sport</li><li>Daily interactions</li><li>Self-organize</li><li>Reduce heroism</li><li>Reflect</li><li>Analytics is code</li><li>Orchestrate</li><li>Make it reproducible</li><li>Disposable environments</li><li>Simplicity</li><li>Analytics is manufacturing</li><li>Quality is paramount</li><li>Monitor quality and performance</li><li>Reuse</li><li>Improve cycle times</li></ol></blockquote><p><strong>书中关于作为CDO如何让数据的价值被CEO认可和信任，这其实就是数据人的目标：</strong></p><blockquote><p>CAOs and CDOs: Earn the Trust of your CEO</p><ol type="1"><li>Earn trust by delivering a journey of value</li><li>Earn trust by delivering quickly</li><li>Earn trust by delivering accurately</li></ol></blockquote><p><strong>获得信任，首先要做到数据是有价值的，并且做到快速交付，高质量交付。</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近看了一些关于 DataOps 的书和文章，对自己的理解做个总结。&lt;/p&gt;
&lt;h2 id=&quot;dataops-要解决什么问题&quot;&gt;DataOps 要解决什么问题？&lt;/h2&gt;
&lt;p&gt;两个价值点，第一是&lt;strong&gt;提高数据生产到价值产出全链路的效率&lt;/strong&gt;，第二是&lt;strong&gt;用数据来持续优化整个数据链路的可用性和价值&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;dataops-是什么&quot;&gt;DataOps 是什么？&lt;/h2&gt;
&lt;p&gt;下面是 Gartner 对 DataOps 的&lt;a href=&quot;https://www.gartner.com/en/information-technology/glossary/dataops&quot;&gt;定义&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>如何做产品定位 - 「Obvious Awesome - How to nail product pos」</title>
    <link href="http://blog.zhengdong.me/2021/02/16/how-to-nail-product-pos/"/>
    <id>http://blog.zhengdong.me/2021/02/16/how-to-nail-product-pos/</id>
    <published>2021-02-16T07:51:23.000Z</published>
    <updated>2021-02-16T08:02:43.581Z</updated>
    
    <content type="html"><![CDATA[<p>书中关于定位的表述，相比著名的 <a href="https://www.amazon.com/Positioning-Battle-Your-Al-Ries/dp/0071373586/ref=sr_1_1?dchild=1&amp;keywords=positioning&amp;qid=1613460532&amp;sr=8-1">Positioning: The Battle for Your Mind</a>，更产品视角，不仅仅是讲述如何在营销战中抓住用户获取胜利，而是如何基于定位去打造产品、迭代产品。</p><p>看完 <a href="https://www.amazon.com/Obviously-Awesome-Product-Positioning-Customers/dp/1999023005/ref=sr_1_1?dchild=1&amp;keywords=obviously+awesome&amp;qid=1613461641&amp;sr=8-1">Obvious Awesome</a>，我理解的重点有三部分，一是究竟什么是定位（Positioning），二是有效定位有哪些组成部分，三是如何通过10个步骤来确定定位。</p><h2 id="什么是定位">什么是定位</h2><p>引言中作者对定位是这么描述的：</p><blockquote><p>Positioning is the act of deliberately defining how you are the best at something that a defined market cares a lot about.</p></blockquote><p>之后用上下文（Context）来做类比：</p><blockquote><p>Context enables people to figure out what’s important. Positioning products is a lot like context setting in the opening of a movie.</p></blockquote><p>作者用电影来举例，比如开场几分钟会让观众大体获知影片的一些关键信息，比如是悲喜剧还是惊悚片。我的理解，产品的定位，就是提供一系列上下文，让客户在第一次看到产品的时候，能理解这个产品是什么，能做什么，他应该关心什么。</p><h2 id="有效产品定位的5个组成部分">有效产品定位的5个组成部分</h2><p><strong>1）Competitive alternatives</strong></p><p>如果我们的解决方案不存在，客户会用什么方式来替代？</p><p><strong>2）Unique attributes</strong></p><p>我们有，但替代方式（竞品）缺少的特性和能力是什么？</p><p><strong>3）Value (and proof)</strong></p><p>这些独有特性能为客户带来哪些价值？</p><p><strong>4）Target market characteristics</strong></p><p>真正关心产品价值的典型客户群特征是什么？</p><p><strong>5）Market category</strong></p><p>为了让客户理解我们提供的价值，我们将产品列入的市场类别是什么？</p><p><strong><em>6）(Bonus) Relevant trends</em></strong></p><p>有哪些行业/市场趋势，能帮助我们让目标客户更好建立对我们产品的兴趣？</p><h2 id="确定定位的10个步骤">确定定位的10个步骤</h2><p><strong>1）理解热爱我们产品的客户</strong></p><p>有效定位的5个组成部分是相互依赖的，环环相扣，该如何开始？</p><p>首先是列出产品最热爱客户的短名单。和这些客户交流，能帮助我们聚焦，找到客户为选择我们是否存在典型模式。如果当前还找不到这些客户，那暂将产品的定位约束放松，先通过产品的迭代和目标客户定向找到这些客户。</p><p><strong>2）组建定位团队</strong></p><p>需要哪些岗位参加进来？带来哪些输出？</p><ul><li><strong>公司负责人（或大公司事业部负责人）</strong> -&gt; 整体的业务策略</li><li>市场 -&gt; 营销信息，受众定位，营销活动</li><li>销售和BD -&gt; 目标客户细分，销售侧客户策略</li><li>客户成功 -&gt; 交付和客户拓展策略</li><li>产品和研发 -&gt; 里程碑和优先级</li></ul><p>组织形式：</p><ul><li>人不宜过多，但每组都需要有人在，才能达成真正共识</li><li>公司外人员来 facilitate 讨论，可以让讨论更高效和平衡</li></ul><p><strong>3）统一定位词汇，去除定位包袱</strong></p><p>统一概念和定义：何为定位、为何重要，有哪些组成部分、如何定义，市场成熟度和竞争环境如何影响产品定位方式？</p><p>为了找出对产品可能新的理解方式，我们需要刻意<strong>摆脱固有思考方式及固有观点</strong>。</p><p><strong>4）列出真正的竞品</strong></p><p>客户和我们看待竞品的方式经常不一样，而他们的观点才是我们定位唯一所关注的。</p><p>找寻竞品最好的办法是回答这个问题：<strong>如何我们的产品不存在，最热爱我们产品的客户会如何做？</strong></p><p><strong>5）分离出我们独有的特性</strong></p><p>有了竞品后，下一步就是分析，相比竞品，是什么让我们不同和更好的？</p><p>需要注意的几个点：</p><ol type="1"><li>列出所有我们有但竞品没有的能力；</li><li>避免使用观点性描述除非有明确事实证明，如“我们提供优秀的客户服务”，“我们有最好的易用性”等；</li><li>聚焦在获客相关特性上，留存相关特性并非不重要，而是只有当客户真正了解我们后，才会发挥作用。</li></ol><p><strong>6）将特性映射到价值场景</strong></p><p>独有特性是起点，但客户更关心的是这些特性对他们有什么价值？</p><p>书中特性到价值映射的举例，从特性（features）到用途（benefits）到客户价值（value）：</p><ul><li>特性 -&gt; your product does or has: One-clink reports</li><li>用途 -&gt; features enable for customers: fast, easy report generation</li><li>客户价值 -&gt; customer is trying to achieve: every part of the organization can make better decisions based on accurate, up-to-date metrics.</li></ul><p><strong>7）确定哪些特性/价值是我们最关心的</strong></p><p>理解产品相比竞品的独有价值后，我们要去找寻客户真正关心哪些价值。</p><p>目标客户群要尽可能聚焦，之后可以扩展更多客户群。两个前提</p><ul><li>该客户群规模足够满足我们的短期商业目标</li><li>该客户群有一致的未解决痛点</li></ul><p><strong>8）选择能让我们胜出的市场类别</strong></p><p>三种选择：</p><ol type="1"><li>Head to Head：定位在既有市场类别，目标成为Top玩家</li><li>Big Fish, Small Pond：定位在既有市场类别，目标是在细分类目胜出</li><li>Create a New Game：建立新市场列别，目标成为Top玩家</li></ol><p><strong>9）借助趋势</strong></p><p>如果有趋势，有风口，我们应该借力，但如果没有，是不影响产品的成功的。</p><p><strong>10）记录定位，用于分享</strong></p><p>定位确认后，需要通过在组织内部的分享，<strong>得到大家的 buy-in，才能被用在品牌传播，营销活动，销售策略，产品决策，客户成功策略中</strong>，才算落地。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;书中关于定位的表述，相比著名的 &lt;a href=&quot;https://www.amazon.com/Positioning-Battle-Your-Al-Ries/dp/0071373586/ref=sr_1_1?dchild=1&amp;amp;keywords=positioning&amp;amp;qid=1613460532&amp;amp;sr=8-1&quot;&gt;Positioning: The Battle for Your Mind&lt;/a&gt;，更产品视角，不仅仅是讲述如何在营销战中抓住用户获取胜利，而是如何基于定位去打造产品、迭代产品。&lt;/p&gt;
&lt;p&gt;看完 &lt;a href=&quot;https://www.amazon.com/Obviously-Awesome-Product-Positioning-Customers/dp/1999023005/ref=sr_1_1?dchild=1&amp;amp;keywords=obviously+awesome&amp;amp;qid=1613461641&amp;amp;sr=8-1&quot;&gt;Obvious Awesome&lt;/a&gt;，我理解的重点有三部分，一是究竟什么是定位（Positioning），二是有效定位有哪些组成部分，三是如何通过10个步骤来确定定位。&lt;/p&gt;
&lt;h2 id=&quot;什么是定位&quot;&gt;什么是定位&lt;/h2&gt;
&lt;p&gt;引言中作者对定位是这么描述的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Positioning is the act of deliberately defining how you are the best at something that a defined market cares a lot about.&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>数据产品增长问题的一个分析框架</title>
    <link href="http://blog.zhengdong.me/2021/01/15/data-product-growth-analysis-framework/"/>
    <id>http://blog.zhengdong.me/2021/01/15/data-product-growth-analysis-framework/</id>
    <published>2021-01-15T14:48:24.000Z</published>
    <updated>2021-01-15T15:02:20.975Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一、从客户的角度来看，我们的客户都是谁？他们的核心痛点是什么？</strong></p><p>我们的客户可能是分析师，业务人员，企业决策层，企业IT团队，甚至企业服务的客户，不同客户的痛点是不同的，进而对产品的期望也不同。这里会面临两个决策点：</p><ol type="1"><li>确定我们真正要服务的客户是哪些？让所有人满意是非常难的。</li><li>对这些客户按角色、数据能力等进行分层，针对定义服务的方式。</li></ol><p>举例：基于客户分层的产品服务方式</p><ul><li>让他们可以快速获知自己关注指标的状态，帮助他们迅速获知面临哪些问题。</li><li>让他们能够在特定业务场景的分析框架下，灵活定义自己的看数视角，获得洞察。</li><li>让他们能够定义自己的分析框架，自助取数和分析。</li></ul><p><strong>二、从交易的角度来看，我们为客户提供了哪些让他们持续使用的价值？我们能否持续高效的创造这些价值，且成本足够低？</strong></p><p>产品提供的功能很多，也许都有用，但不同功能对客户的吸引力是不同的。这里要弄清楚两个问题：</p><ol type="1"><li>找到产品吸引用户使用的价值点究竟有哪些？分析各个价值点对用户的粘性。</li><li>从生产成本的角度来评判这些价值，由我们提供是否合适？即回答”为什么是我们“这个问题。（产品3问：1. 我们的客户是谁？2. 我们能为我们的客户做什么？3. 为什么是我们？）</li></ol><p>举例：基于价值分层的产品需求分类</p><ul><li>底线需求：一定要做。</li><li>够用就好：适可而止，控制成本。</li><li>越多越好：持续投入，但生产端要提效降本。</li><li>惊喜：阶段性适量提供。</li></ul><p><strong>三、从平台的角度来看，我们的运营和产品分发体系是否足够精准让对的人看到对的内容？我们是否有一套内容价值评估和汰换机制？</strong></p><p>平台提供的服务趋向多样化是平台内生的动力，供和需的多方参与，会带来复杂性和问题。有两件事是要去做：</p><ol type="1"><li>供需匹配，建立内容的精准分发能力，基于推荐或定点运营，持续做平台提效。</li><li>反馈系统，建立一套内容价值评估和反馈收集能力，基于此做汰换，持续做平台瘦身。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;一、从客户的角度来看，我们的客户都是谁？他们的核心痛点是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们的客户可能是分析师，业务人员，企业决策层，企业IT团队，甚至企业服务的客户，不同客户的痛点是不同的，进而对产品的期望也不同。这里会面临两个决策点：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;确定我们真正要服务的客户是哪些？让所有人满意是非常难的。&lt;/li&gt;
&lt;li&gt;对这些客户按角色、数据能力等进行分层，针对定义服务的方式。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;举例：基于客户分层的产品服务方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让他们可以快速获知自己关注指标的状态，帮助他们迅速获知面临哪些问题。&lt;/li&gt;
&lt;li&gt;让他们能够在特定业务场景的分析框架下，灵活定义自己的看数视角，获得洞察。&lt;/li&gt;
&lt;li&gt;让他们能够定义自己的分析框架，自助取数和分析。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关于未来内容型数据产品方向的几个观点</title>
    <link href="http://blog.zhengdong.me/2020/12/06/view-of-the-future-data-product-trends/"/>
    <id>http://blog.zhengdong.me/2020/12/06/view-of-the-future-data-product-trends/</id>
    <published>2020-12-06T15:54:42.000Z</published>
    <updated>2020-12-08T16:27:13.662Z</updated>
    
    <content type="html"><![CDATA[<p>这里的内容型数据产品指的是以提供内容为主要目标的数据产品，区别于以提供技术能力为主要目标的工具型数据产品，如 Tableau 及类似的可视化 BI 产品、Zeppelin 及类似的分析、协作产品等。</p><h2 id="内容型数据产品的3个方向">内容型数据产品的3个方向</h2><p>未来内容型数据产品方向，我认为是如下三个：</p><ol type="1"><li>数据产品基于BI或低代码工具搭建而成；</li><li>数据产品和业务产品合二为一；</li><li>交互式、对话式分析成为数据产品的基本能力。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li></ol><h3 id="一数据产品基于bi或低代码工具搭建而成">一、数据产品基于BI或低代码工具搭建而成</h3><p>我们做一个数据分析报告，或者数据探索的目的是什么？我的理解是做4件事，<strong>描述</strong>业务发生了什么，<strong>诊断</strong>为什么发生，<strong>预测</strong>将要发生什么，以及<strong>决策</strong>要做什么。</p><p>常见的内容型数据产品主要覆盖描述和诊断环节，首先让大家看清数，看懂数，才能更好的决策，更好做行动计划。看清数，要做到数据能反应业务现状，看懂数，要做到数据包含体系化分析思路。看起来不难，可现状是什么？</p><p>业务的打法和重点策略在竞争中会经常调整，对数据产品而言，需求多变且交付时间紧是常态，如果业务的策略调整等一两个月后产品才有数看，何谈看清数。</p><p>数据产品在建设初期会有明确的产品逻辑设计，但在后期的迭代过程很多走向了功能堆砌，毕竟需求都是不断在增加的，毕竟推翻重构时间上决不允许，“又不是看不到数？”。带来的问题是用户分析一个问题，可能需要若干次产品功能跳转，很难看懂数。</p><p>现在很多 BI 工具都提供了产品搭建能力，数据产品的开发过程可以转化为：1）制作可视化报表，2）设计报表的组织形式，3）独立产品发布，整个过程都是基于可视化操作和配置而成，无需独立开发。另外，低代码平台这两年也很热，通过低代码平台可视化搭建的能力组织分析报表也是一个途径。</p><p>这样带来了两个好处，1）基于搭建能力，可以做到快速响应需求进行功能新增和调整，大大缩短业务策略调整和能看清数之间的时间消耗；2）产品的组织逻辑调整不再依赖产品经理和各端开发工程师的协同，可以做到基于不同时期的分析框架来快速重组产品，让企业构建统一分析体系并迭代成为可能。</p><p>那看起来内容型数据产品变成了一个个数据报表的载体，如果这样，BI分析师是不是比数据产品经理更适合做内容型数据产品的产品经理？</p><p>是的。但我觉得内容型数据产品不应该仅仅只是描述业务发生了什么，不仅仅只是助力用户去诊断为什么发生。</p><h3 id="二数据产品和业务产品合二为一">二、数据产品和业务产品合二为一</h3><p>内容型数据产品的基本能力是以产品化的形态，帮助用户看清业务现状，引导用户洞察出业务面临的问题，做不到、做不好，都是不应该的。</p><p>但就像“懂得很多道理，却依然过不好这一生“一样，对用户而言，当看清、看懂数后，面临的最大问题往往是谁能告诉我该做什么？可能会发生什么？能怎么去做？</p><p>在一个企业内部，除了数据产品外，还有很多”后台“产品，比如进销存、供应链、广告投放、CRM等系统，权且称做业务产品，大量业务策略的落地是靠各部门的业务人员操作这些产品达成的。一个数据驱动业务的决策流程如下：通过内容型数据产品获得洞察，业务线进行理解、讨论和决策，业务线制定行动计划，业务人员操作业务产品做执行，通过内容型数据产品进行效果追踪。</p><p>整个流程涉及到多方协同，大家对数据的理解程度可能不一，涉及多个系统，数据链路也可能割裂，整体效率低，反馈链路长。存在这些问题恰恰是数据产品的机会，不应该独守一隅，要打通数据和行动，建立诊断、行动、效果回收、诊断的闭环，也许以后不存在独立的数据产品，业务产品本该就能做到用数据描述现状，基于业务诊断问题并制定计划，做行动，做效果评估和优化调整，典型的<a href="https://en.wikipedia.org/wiki/PDCA">PDCA</a>循环：Observation、Plan、Do、Check、Adjust。</p><p>举个例子，产品化支持增长框架 AARRR，除了支持新客和激活，留存，NPS，收入等分析能力外，还能做什么？本质上，AARRR 是一个拆解逻辑，每一项是可被独立分析、诊断及优化的。拿新客诊断举例，比如发现整体拉新效果不好，诊断到是因为有几个渠道转化率太低，产品能给出策略建议，比如需要调整渠道的投放分布，用户 review 后直接通过产品的行动点操作即完成整个流程。</p><p>我想以后数据驱动业务的产品体系是这样的，顶层是服务决策层的决策数据产品，对，这是内容型数据产品，下面是数据和业务融合的新型业务产品，分析和诊断形成的洞察可以直接做业务行动，业务的策略反向可以促进分析和诊断模型的优化和构建，再下面是数据资产。</p><p>BI分析师做好决策数据产品，数据开发工程师做好数据资产，数据和业务产品合二为一才是值得数据产品经理去深耕和发挥价值的领域。</p><p>数据和行动闭环的打通，也为真正做到数据智能打下了基础。</p><h3 id="三交互式对话式分析成为数据产品的基本能力">三、交互式、对话式分析成为数据产品的基本能力</h3><p>交互式和对话式分析是指数据产品不再是固化的展示数据指标，而是开放更大灵活性给用户，用户参与其中，通过交互选择或对话问问题的方式，定义自己的看数视角，获得洞察。</p><p>以用户行为转化漏斗分析举例，常规数据产品会首先根据业务诉求定义转化过程重要节点，数据开发进行需求开发，然后通过数据的可视化展现服务用户。而交互式分析模式首先是对转化分析方式进行抽象：转化漏斗分析是对漏斗窗口期内，所有满足限制条件的用户行为，按既定步骤顺序的转化计算，以漏斗图的可视化形式展现。产品模块定义如下：1）漏斗名称设置组件，2）漏斗窗口周期设置组件，3）漏斗步骤设置模块，其中每项步骤包含用户行为选择和限制条件配置，4）漏斗图展现组件。至于对哪些行为做分析，是否需要对该行为再做条件筛选，关联多长时间的数据做时间序列追踪等，交由用户选择，即席查询。对话式分析，是指这一过程用语言或语音对话的方式来进行，用户可以通过对话主动触发，平台也可以基于智能判断，推荐用户可关注的问题，比如 Google Analytics 的 Insights 功能。</p><p>这两种分析模式，对技术会带来很多挑战，如何做到千人千面的分析查询都能快速的反馈结果，如何做到很好的自然语言理解和推断能力，尤其在数据分析这个需要很多业务上下文知识，对语义歧义容忍度差的领域，等等。但技术在发展，这些问题迟早会被解决。</p><p>对产品而言的挑战的是什么？前面我们看到很多“灵活”字样，做过产品的应该知道，这暗含另一个问题，即灵活意味着需要用户 Input，意味着用户一开始可能不会用，也就是产品拥有很高的上手门槛。所以，泛化的交互式、对话式分析产品，泛化的数据智能产品，往往很难落地。做不出，做出来效果不好，做出来效果好但用户觉得不会用。那怎么办？回到做数据的一句老话，“数据的价值必须来自场景”，可以先从聚焦场景出发，比如先把用户行为分析这一个场景做透。</p><p>数据分析的大众化，数据科学的平民化，一定是趋势和未来。数据分析大众化的趋势，就是要降低数据获取和分析的难度，做到不依赖分析师，不依赖数据开发工程师，交互式分析是要解这个问题。数据科学平民化的趋势，就是要降低数据探索和洞察的难度，不需要用户既懂数据，又懂算法，对话式分析是要解这个问题。</p><h2 id="内容型数据产品经理的3个核心能力">内容型数据产品经理的3个核心能力</h2><p>前面讲了内容型数据产品的三个方向：1）数据产品基于BI或低代码工具搭建而成，2）数据产品和业务产品合二为一，3）交互式、对话式分析成为数据产品的基本能力。对于内容型数据产品经理而言，在变迁过程中如何持续保持个人竞争力，我认为最重要的是如下三项能力。</p><p><strong>1、对所服务业务的目标评估体系有好的认知</strong></p><p>先回到做产品的灵魂三问：1）我们的客户是谁？2）我们能为我们的客户做什么？3）为什么是我们？内容型数据产品的客户是谁？一开始一定是业务 Leader，得解决他的问题，他满意才有落地可能。我们能为他做什么？让他看清数，在清晰了解现状和环境的前提下做决策。为什么是我们？我们做出的产品体验优秀人人都能无脑使用？我们做出的产品拥有非常酷炫的可视化效果？都不是，是让业务 Leader 能看清数。而要让他看清数，关键依赖于你对业务目标及其评估体系的认识，哪怕分析结论是朴素的一张张表格，还是那种巨长的中国式报表，但能让现状和环境被看清，已经很优秀。接下来才是去选择合适的数据可视化形式，让用户看懂数。</p><p><strong>2、能基于业务现状和商业逻辑抽象分析框架和行动点</strong></p><p>数据和业务产品的融合能发挥效力，对产品设计者的要求我总结了9个字：知重点，有框架，能行动。知重点是指基于对业务商业逻辑和现状的认知，能定义当前重点问题；有框架是指熟知主流的分析框架，如增长框架 AARRR、用户营销模型 AIPL 等，且具备基于业务构建分析框架的能力，分析框架为的就是统一语境和思路，拆解问题，分而治之；能行动是指具备数据洞察可行动的机制建设能力，促进通过数据洞察得出的策略在业务落地，如做新客增长可能需要建立对投放系统的反馈机制，做留存复购可能需要对接权益投放系统支持权益的动态分发。</p><p><strong>3、对产品迭代的提效有精益求精的执念</strong></p><p>内容型数据产品的迭代提效，不只是开发工程师的事情，数据产品经理作为产品 Owner，要时刻想着如何更快把产品做出来，因为需求一定会变，甚至反复，时间一定会很紧，比如以小时计。在做产品设计时，对这些问题要有预判，针对性确定产品方案。</p><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>本文仅代表个人观点。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;这里的内容型数据产品指的是以提供内容为主要目标的数据产品，区别于以提供技术能力为主要目标的工具型数据产品，如 Tableau 及类似的可视化 BI 产品、Zeppelin 及类似的分析、协作产品等。&lt;/p&gt;
&lt;h2 id=&quot;内容型数据产品的3个方向&quot;&gt;内容型数据产品的3个方向&lt;/h2&gt;
&lt;p&gt;未来内容型数据产品方向，我认为是如下三个：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;数据产品基于BI或低代码工具搭建而成；&lt;/li&gt;
&lt;li&gt;数据产品和业务产品合二为一；&lt;/li&gt;
&lt;li&gt;交互式、对话式分析成为数据产品的基本能力。&lt;a href=&quot;#fn1&quot; class=&quot;footnote-ref&quot; id=&quot;fnref1&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;一数据产品基于bi或低代码工具搭建而成&quot;&gt;一、数据产品基于BI或低代码工具搭建而成&lt;/h3&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关于未来数据开发技术方向的几个观点</title>
    <link href="http://blog.zhengdong.me/2020/12/05/view-of-the-future-data-dev-technology/"/>
    <id>http://blog.zhengdong.me/2020/12/05/view-of-the-future-data-dev-technology/</id>
    <published>2020-12-05T12:17:48.000Z</published>
    <updated>2020-12-05T16:55:21.308Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据开发技术的3个方向">数据开发技术的3个方向</h2><p>未来数据开发技术方向，我认为有三个，首先是流批一体成为主流开发模式，其次是代码自动化技术走向成熟，第三是 OLAP Cubes 终将衰落。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><h3 id="一流批一体成为主流开发模式">一、流批一体成为主流开发模式</h3><p>先说说我看到的数据开发的历史。</p><ol type="1"><li>“远古”时代，通过写 SQL 脚本抽取 OLTP 数据库中数据进行分析和统计，大量查询有可能把数据库拖挂；</li><li>OLAP 分析成为数据库的一项重要能力，这个时候，可以写 SQL，也可以写 Python 代码等来进行数据分析和统计，但面对不断增长的数据量，数据库性能遇到挑战；</li><li>Hadoop 技术的引入和不断成熟，海量数据的离线存储、计算和调度问题得到解决；</li><li>Storm 让海量数据的实时计算成为可能，促进了一大批实时数据产品的出现，也促进了 Lambda 数据架构的出现和流行；</li><li>Kafka、Spark、Flink 等技术的流行，整个数据链路的全流式计算成为可能，Kappa 架构出现和流行。</li></ol><p>从单机 OLAP 到 Lambda 到 Kappa 的演进，数据链路上的问题、数据计算层面的问题得到了很好解决。那未来一切皆流式，一切皆实时是否可行？是否经济？我们的数据架构还存在什么问题？</p><p>列举几个数据领域常见的问题：</p><ul><li>数据产品实时和离线模块同一指标数值不同，因为指标计算离线、实时是单独开发，单独存储的，口径有差异；</li><li>同一口径的数据指标，需要离线和实时各开发一份代码，因为彼此的计算引擎不同，编程范式不同，即使都用 SQL 编写，也很难完全复用；</li><li>离线数仓和实时数仓彼此独立存在，带来双重的存储和维护成本，因为离线和实时任务有不同的数仓分层及存储体系。</li></ul><p>要解决这些问题，需要实时和离线计算的融合，称作流批一体架构。这里说的融合不是用实时计算替代所有离线计算，离线和实时计算有各自适用的场景，而是对于数据的下游应用来说，不用去关注数据来自实时还是离线，对于数据开发工程师来说，不用去关注开发的是实时还是离线代码，实时、离线只是调度层面的概念。融合过程根据现状的不同可以分两个阶段，第一是存储统一，第二是代码统一。</p><h4 id="实时离线的存储统一">实时、离线的存储统一</h4><p>这个阶段，实时和离线任务还是单独开发和执行的，但不再区分存储介质，比如常见的离线结果存 MySQL，实时结果存 HBase 方案，改成统一存储到海量数据高频读写皆优的存储计算引擎，如 Apache <a href="https://kudu.apache.org">Kudu</a> &amp; <a href="https://impala.apache.org">Impala</a>，<a href="https://www.alibabacloud.com/product/hologres">Alibaba Hologres</a> 等。</p><p>存储统一可以解决下游应用需要通过不同逻辑对接实时、离线数据的问题，例如统一后，同一张表取当天的数据就是截止目前为止的实时数据，取昨天的数据，就是 T-1 的离线数据。另外，也为后续第二阶段的代码统一做了铺垫，因为已经做到实时、离线统一存储，代码统一过程对下游是无感知的。</p><h4 id="实时离线的代码统一">实时、离线的代码统一</h4><p>实时和离线代码被统一为一份，通过调度设置来区分是实时还是离线批处理。这个阶段存在两个挑战。</p><p>第一个挑战是对计算引擎的，需要实时计算引擎兼具批任务执行能力，且做到流批 API 的统一，这块能力在 <a href="https://flink.apache.org/roadmap.html">Flink Roadmap</a> 里，Blink 当前已经支持的不错。</p><p>第二个挑战是对数仓架构的，实时和离线数仓需要统一，存在两个问题，1）新流批一体任务如何和所替代的老的离线任务保持统一的上游依赖？这个问题在存储、计算分离的计算平台架构下比较容易解决，打通元数据，不同计算引擎访问统一存储；2）流批一体任务依赖的上游任务可能未做流批一体，比如为了更精准的反作弊，需要独立开发离线任务通过长周期历史数据做计算，即如何解决流批一体任务依赖双重上游数据输入的问题？这个问题可以通过对该上游任务的结果表在 Schema 层面做统一来解决，如构建镜像表，根据调度模式的不同来映射依赖上游哪份数据。</p><h3 id="二代码自动化技术走向成熟">二、代码自动化技术走向成熟</h3><p>代码自动化，有两个方向，一是代码的自动生成，二是代码的自动优化。</p><h4 id="代码的自动生成">代码的自动生成</h4><p>数仓模型设计的实施工作流包含业务和需求调研，架构设计，规范定义，数据建模四个过程。</p><ul><li>架构设计指以维度建模为理论基础，基于业务和需求调研的结果，进行整体数仓设计，包含确定数据域，定义每个数据域下面的业务过程及相关维度两件事情；</li><li>规范定义指定义指标体系，包括原子指标，业务限定如修饰词、时间周期，以及派生指标，由原子指标和业务限定组合而成；</li><li>数据建模主要包括维度及属性的规范定义，维表、明细事实表和汇总事实表的模型设计。</li></ul><p>现在已经有数据研发平台可以做到可视化数据模型设计：配置化定义维度、业务过程和事实表元数据，自动生成维表和事实表；可视化关联字段的原子指标和业务限定，配置化定义派生指标口径，自动生成汇总表。整个模型设计过程代码是自动生成的，当然，一些复杂指标计算逻辑是通过代码片段的形式作为配置项提交。</p><p>代码的自动生成除了提升开发效率外，还带来额外的好处，因为计算代码是动态生成的，汇总表是否生成真正的物理表，对用户是透明的，平台可以根据成本、性能、效率等的考虑，来动态决定是构建物理表（也就是OLAP Cube），还是只是一个视图，背后是直接下发查询到事实明细表。</p><p>大家有兴趣可以了解下阿里的 <a href="https://www.aliyun.com/product/dataphin">Dataphin</a> 产品。</p><h4 id="代码的自动优化">代码的自动优化</h4><p>实时/离线计算引擎的不断发展演进，越来越多人肉在做的优化最佳实践会被集成到引擎里，做到在线识别、自动优化。</p><p>比如 Join 长尾（倾斜）问题，有一个优化方式是把热点数据提取出来，然后拆分任务，用大小表的 mapjoin 机制来提速；比如 count distinct 倾斜问题，可以基于热点字段做数据的二次分发，将查询拆成两层，内层子查询基于二次分发的数据做聚合，外层查询再按热点字段聚合。后者已经被 Flink <code>partialAgg</code> 机制所支持，开发人员使用普通 SQL 开发任务即可。相信这些有规可循的优化“套路“会越来越多地被集成到计算引擎中。</p><h3 id="三olap-cubes-终将衰落">三、OLAP Cubes 终将衰落</h3><p><a href="https://en.wikipedia.org/wiki/OLAP_cube">OLAP Cube</a> 又称 Data Cube，工程实践上是对（明细）数据表基于合适的维度组合（基于业务确定的维度组合或基于重要维度的笛卡尔积组合）做预先聚合计算，典型的计算机领域以空间换时间案例。</p><p>这种预计算模式，通过为下游应用提供稳定的查询性能，长久来促进了数据仓库的发展，我们通常说的集市层“百花齐放”，快速响应业务诉求，指的就是 OLAP Cubes 的建设。数据仓库建模理论，如 Kimball 的维度建模理论，本质上就是解决如何基于业务的分析诉求，科学的定义数据仓库中数据的组织方式，让数据开发工程师更好更容易的构建 OLAP Cubes。</p><p>技术的限制让这种模式存在并流行，这种模式反过来又在塑造数据团队的组织形式和职能，成为一种行业标准。做个假设，如果我们当前拥有极为充足的计算能力，很便宜的内存资源，还有能高效利用它们提供足够优秀查询性能的数据库，我们是否还需要花费大量人力基于明细数据去开发一个个应用层汇总表来解决多样的数据查询诉求？</p><h4 id="计算技术的成熟">计算技术的成熟</h4><p>第一个因素是摩尔定律，带来了计算和存储成本的不断降低，公有云的高速发展，按需购买，按量付费的模式，进一步降低了数据的存储和计算成本。</p><p>第二个因素是类MPP计算架构，列存储模式数据查询引擎的技术突破和成熟，同等资源下，能提供成倍甚至几十倍的查询性能提升。</p><p>从技术上来看，停止建设 OLAP Cubes，所有请求直连明细数据是可能的。但从业务上来看，所有的数据查询请求直连明细数据，存在两个潜在问题：1）查询请求过于复杂，不易理解，且容易出错；2）数仓汇总层会变得很薄，业务人员要从明细层取数，效率变低。</p><h4 id="数据应用的契机">数据应用的契机</h4><p>数据应用端的两个发展趋势一定程度上可以解决上述潜在问题。</p><p>第一个趋势是BI工具的演化，从提供优秀的报表制作及数据可视化能力，到兼具高级分析的”计算“能力。用户不再需要费脑力去思考如何写复杂的取数 SQL，而是通过 BI 工具的拖拽可视化，以及简单易用的计算字段配置来进行数据的分析和探索，如 YoY/MoM/DoD 对比、年/月/日汇总和趋势分析、字段级联组织和下钻分析等，都是通过系统配置自动支持，不用写 SQL。</p><p>第二个趋势是交互式/对话式查询在数据产品上的应用越来越多。这类数据产品模式的目标是提供更大的灵活性给用户，数据产品不仅仅只是看数，而是用户参与其中，定义自己的看数视角。以用户行为转化漏斗分析举例，常规数据产品会首先根据业务诉求定义转化过程重要节点，数据开发进行需求开发，然后通过数据的可视化展现服务用户。而交互式分析模式首先是对转化分析方式进行抽象：转化漏斗分析是对漏斗窗口期内，所有满足限制条件的用户行为，按既定步骤顺序的转化计算，以漏斗图的可视化形式展现。产品模块定义如下：1）漏斗名称设置组件，2）漏斗窗口周期设置组件，3）漏斗步骤设置模块，其中每项步骤包含用户行为选择和限制条件配置，4）漏斗图展现组件。至于对哪些行为做分析，是否需要对该行为再做条件筛选，关联多长时间的数据做时间序列追踪等，交由用户选择，即席查询。</p><p>概括来说，就是使用可视化分析工具替代取数 SQL 开发，产品化构建交互式分析场景替代集市主题表建设。</p><h2 id="数据开发从业者的3个核心能力">数据开发从业者的3个核心能力</h2><p>前面讲了数据开发技术的三个方向：1）流批一体成为主流开发模式，2）代码自动化技术走向成熟，3）OLAP Cubes 终将衰落。对于数据开发从业者而言，在技术的发展中，如何持续保持个人竞争力，我认为最重要的是如下三项能力。</p><p><strong>1、能深入理解你所服务的业务</strong></p><p>只有深入理解业务，才能真正知道当前业务处在什么阶段，碰到了什么问题，重点目标是什么。对应到企业的数据建设，一定要先解决“为什么”的问题，当前数仓服务的业务现状是什么，为了解决业务什么问题，期望达到什么目标，这些是无法靠技术自动化解决的。然后才是模型设计、实施落地。</p><p><strong>2、有把数据做深的能力</strong></p><p>数据会被用来搭建一个个分析报表，服务一个个数据产品，好像数据产生后，就和数据开发从业者无关了，以至于从业者很多自嘲是“人肉SQL机器”，是“数据搬运工”，也经常被合作方称做“ETL工程师”。把数据做深的能力是指生产数据之外，能持续去思考从这些数据里能获取什么，不管是通过数理统计还是机器学习，探索能否挖掘出推动业务增长的洞察，以及行动指引，是做“数据掘金者”。</p><p><strong>3、具备数据链路的全局观</strong></p><p>数据链路的全局观不仅仅是清楚整个数据架构是什么样子，熟悉数据是如何流转的，更是能做数据链路的全局优化。如整个数据链路的稳定性保障，数据资产的组织和管理机制设计，数据的全链路价值评估、成本治理，数据的质量管理及测试、监控机制的建设等。</p><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>本文仅代表个人观点。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;数据开发技术的3个方向&quot;&gt;数据开发技术的3个方向&lt;/h2&gt;
&lt;p&gt;未来数据开发技术方向，我认为有三个，首先是流批一体成为主流开发模式，其次是代码自动化技术走向成熟，第三是 OLAP Cubes 终将衰落。&lt;a href=&quot;#fn1&quot; class=&quot;footnote-ref&quot; id=&quot;fnref1&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;一流批一体成为主流开发模式&quot;&gt;一、流批一体成为主流开发模式&lt;/h3&gt;
&lt;p&gt;先说说我看到的数据开发的历史。&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;“远古”时代，通过写 SQL 脚本抽取 OLTP 数据库中数据进行分析和统计，大量查询有可能把数据库拖挂；&lt;/li&gt;
&lt;li&gt;OLAP 分析成为数据库的一项重要能力，这个时候，可以写 SQL，也可以写 Python 代码等来进行数据分析和统计，但面对不断增长的数据量，数据库性能遇到挑战；&lt;/li&gt;
&lt;li&gt;Hadoop 技术的引入和不断成熟，海量数据的离线存储、计算和调度问题得到解决；&lt;/li&gt;
&lt;li&gt;Storm 让海量数据的实时计算成为可能，促进了一大批实时数据产品的出现，也促进了 Lambda 数据架构的出现和流行；&lt;/li&gt;
&lt;li&gt;Kafka、Spark、Flink 等技术的流行，整个数据链路的全流式计算成为可能，Kappa 架构出现和流行。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>2018年的两段记录</title>
    <link href="http://blog.zhengdong.me/2020/11/27/some-thoughts-in-2018/"/>
    <id>http://blog.zhengdong.me/2020/11/27/some-thoughts-in-2018/</id>
    <published>2020-11-27T15:40:45.000Z</published>
    <updated>2020-12-10T14:15:08.841Z</updated>
    
    <content type="html"><![CDATA[<p>整理写的东西，发现18年的这几天，写过这么两段话，当时在 Vegas 参加 AWS re:Invent。</p><p>第一段是关于在中国做 to B。</p><blockquote><p>中国做 to B 相比美国难做（重且周期长），是因为中国目前不是一个契约社会，是一个感情社会。很多客户在接受 B 端企业服务方面，还处于婴孩期，倔强任性，什么都要，无视契约，过度重视服务方表现出来的投入力度，即感情分。当然这些客户会随着发展成长起来，很多区域已经有这样的趋势。</p></blockquote><p>第二段是关于在集团公司里面搞阿米巴解决中后台价值难评估问题。</p><blockquote><p>做公司内部平台、中台等支撑业务会碰到很多问题，通过内部结算来体现价值，来确定投入规模，让财务、HR来横向协同、处理集团各事业部和平台中台部门的结算，是很难做好的。不懂技术，在冲突问题上，很难有大的规划，来定夺取舍。一个大公司，平台中台帮助业务做大，然后从大的业务获得更多的财务回报，来保障研发，从而让企业新增的小业务能够直接享受这些研发成果，助力新业务创新，这是平台中台的根本。如果业务做大了后，认为支出过高，便用安全、投入、需求响应等理由投入人力自研基础组件，去重复造轮子，企业的平台中台很难做好，毕竟出不了成绩，决策层会不认可。后果是小业务基本很难起来，最后可能变成了大业务有钱可以做内部创新，集团公司层面的业务创新却因为部门结算成本的问题越来越难做。解决集团公司平台中台技术协同问题有两个解，一个是横向技术管理，如公司确定CTO或者建设技术委员会，并且给予充分授权。二是打破集团公司内部的各个山头，让技术管理者能够跨部门，在业务、平台中台之间周期调派，让大家开放起来，而不是守着、扩充着自己的势力范围，生怕别人进来占了自己的自留地。</p></blockquote><p>两年过来，新的感想。第一段，不是契约社会只是一个角度，相比发达资本主义国家，我们的「商业社会」发展不充分，在很多领域没有形成完整的产业链、上下游意识，尤其在知识产品上。因而企业要么付费意愿弱，觉得这服务不值，要么宁愿一杆子捅到底都自己做，成本虽高但觉得安全。未来企业愿意购买服务来提升自己的商业效率一定是主流，比如充分竞争的零售行业企业付费意愿已经很强。看好 to B，尤其细分领域的 SaaS 服务。</p><p>第二段，财务算清是必要的，但目标是让前台业务的财务状况更清晰，看清业务才能更好决策发展方向。中后台完全按照内部结算来评估价值，可能带来的问题比解决的问题大很多。扪心问，一个企业什么时候会对中后台做强成本考核？是不是前台业务发展变缓甚至停滞的时候？回想起杰克韦尔奇在「商业的本质」一书里写的企业面对创伤如何补救的一条建议：</p><blockquote><p>摆脱困境的确并非易事，但如果留不住那些最优秀的人才，你永远不可能摆脱困境。因此，在公司面临困境之际，领导者不要在本能驱使下裁员降薪，而是要逆本能而动，采取一些鼓舞人心的举措，短期性的措施如涨薪，长期性的措施如根据其业绩表现给予更多的公司股份，也就是说要尽量想办法留住人才，而不是减少人才。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;整理写的东西，发现18年的这几天，写过这么两段话，当时在 Vegas 参加 AWS re:Invent。&lt;/p&gt;
&lt;p&gt;第一段是关于在中国做 to B。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;中国做 to B 相比美国难做（重且周期长），是因为中国目前不是一个契约社会，是一个感情社会。很多客户在接受 B 端企业服务方面，还处于婴孩期，倔强任性，什么都要，无视契约，过度重视服务方表现出来的投入力度，即感情分。当然这些客户会随着发展成长起来，很多区域已经有这样的趋势。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第二段是关于在集团公司里面搞阿米巴解决中后台价值难评估问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;做公司内部平台、中台等支撑业务会碰到很多问题，通过内部结算来体现价值，来确定投入规模，让财务、HR来横向协同、处理集团各事业部和平台中台部门的结算，是很难做好的。不懂技术，在冲突问题上，很难有大的规划，来定夺取舍。一个大公司，平台中台帮助业务做大，然后从大的业务获得更多的财务回报，来保障研发，从而让企业新增的小业务能够直接享受这些研发成果，助力新业务创新，这是平台中台的根本。如果业务做大了后，认为支出过高，便用安全、投入、需求响应等理由投入人力自研基础组件，去重复造轮子，企业的平台中台很难做好，毕竟出不了成绩，决策层会不认可。后果是小业务基本很难起来，最后可能变成了大业务有钱可以做内部创新，集团公司层面的业务创新却因为部门结算成本的问题越来越难做。解决集团公司平台中台技术协同问题有两个解，一个是横向技术管理，如公司确定CTO或者建设技术委员会，并且给予充分授权。二是打破集团公司内部的各个山头，让技术管理者能够跨部门，在业务、平台中台之间周期调派，让大家开放起来，而不是守着、扩充着自己的势力范围，生怕别人进来占了自己的自留地。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>谈谈数据产品的商业化</title>
    <link href="http://blog.zhengdong.me/2019/01/16/data-product-creating-and-selling/"/>
    <id>http://blog.zhengdong.me/2019/01/16/data-product-creating-and-selling/</id>
    <published>2019-01-16T13:50:15.000Z</published>
    <updated>2020-12-02T16:12:21.653Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.zhengdong.me/2019/01/07/speaking-of-a-data-team/">上篇</a>文章以一个数据团队发展的视角，总结了数据团队要做的事。当然，一些企业业务复杂起来之后，数据团队的职能也会发生分工，负责基础数据建设的团队，将数据集成、治理、资产管理、质量管控等工具及规范做掉，同时构建数据仓库的公共层并对上游业务以产品化和服务化的形式提供支持，现在比较热的「数据中台」概念就是指这块事情，和负责业务数据建设的团队，基于公共层数据，直接对接业务，让数据产品化、智能化，赋能业务发展。</p><h2 id="数据产品的四个层次">数据产品的四个层次</h2><p>这篇文章，主要想聊下数据产品，在我的理解里面，数据产品可以分为以下四个层次。</p><p>首先是通用的数据分析及可视化工具，能够连接各种数据，解决分析师、运营等岗位人员查看和分析业务数据的需求，如进行数据的多维分析，数据报告的制作等工作。</p><p>其次是场景化的数据分析产品，通用工具只解决了获取和分析数据的需求，但其实很难要求每个岗位都有好的数据分析能力，知道怎么用数据、怎么用好数据，知道数据的价值。场景化数据产品指的是用分析师沉淀下来的分析思路或分析模型来组织和展示数据，降低数据分析的门槛，提高数据化运营的效率。比如固化 ”AARRR“ 分析模型的用户分析和流量分析产品、活动大促的专题分析产品，面向业务场景的实时数据大屏产品等。</p><p>第三是数据嵌入业务系统的能力和服务，让业务系统可以很方便的连接和使用数据，迅速实现业务数据化。拿精准营销或用户运营系统举例，业务研发团队只需要做好系统流程相关的开发，如营销渠道管理、人群筛选方式和逻辑、触达用户途径和技术对接等，而基于用户特征及行为的分群、画像能力、高性能的数据检索、聚合能力，则由这类数据产品来统一以服务化或内嵌的方式提供。</p><p>第四是数据决策类产品，集成业务知识和数据智能的技术及能力，除了用数据描述业务现状，诊断业务问题外，能进行业务预测和决策支持，比如基于趋势预测、行业洞察直接服务高层管理者的决策。</p><h2 id="数据产品的商业化">数据产品的商业化</h2><p>第一二层次的数据产品，要么通用，要么聚焦场景，通过泛化形成与企业业务细节无关的通用数据产品是可行的，行业里有很多企业在做，也早已被证明是能赋能企业，促进数据化决策效率，降低数据化运营的门槛和成本。</p><p>接下来谈谈在商业化赋能企业的历程中，我的一些收获。</p><h3 id="三个取舍">三个取舍</h3><p>我们从服务自身业务出发，对数据产品提的要求是要足够灵活是真正的多维分析，要有强大的探索分析和可视化能力，还要具备非常好的用户体验。“人人都是数据分析师”的口号听起来很好。</p><p>但真正作为软件服务提供商，面对外部企业，碰到了很多问题。</p><h4 id="客户和用户">客户和用户</h4><p>服务自身业务的时候，我们面对的是一个个用户，所以虽然是 to B 产品，但可以用 to C 的方式去触达和运营产品。</p><p>面对外部企业，很多时候，买单决策方（即客户），和产品使用方（即用户），是不一样的，彼此的目的、期望和利益也不同。比如客户是希望购买了产品后，能解决企业什么问题，如何在众多厂商中选择最佳的供应商，企业采购的预算如何等，用户则往往关注产品是否能解决工作中的问题，是否符合自己以往的使用习惯，是否稳定，是否支持某某功能等。</p><p>一味强调产品的功能往往是无法吸引客户的，也会陷入厂商之间比 feature 比价格这种低质的竞争中。基于产品解决客户实际问题和痛点的方案输出，会非常重要，也是产品要去重视和沉淀的能力。当然，落地到企业里真正被用起来，产生多大的价值是要依赖用户的，无视用户需求也很难成功。</p><h4 id="阅览者和编辑者">阅览者和编辑者</h4><p>用户用产品主要完成两件事，通过分析探索，形成决策依据，或者通过数据可视化，制作数据报告。</p><p>数据产品的核心能力往往会倾向在数据分析和可视化能力方面，让用户可以深度探索数据，便捷做可视化报告。可以称这些用户为编辑者。</p><p>数据报告要被大量消费才有价值，看数据报告的人（称之为阅览者），和做数据报告的人即编辑者，很多时候是不同的，尤其在岗位职能比较细化的中大型企业里，阅览者往往多过做编辑者，并且很多阅览者的决策层级也高于编辑者。</p><p>不能忽视阅览者的诉求，比如怎么解读数据报告，怎么管理数据报告，对数据有疑惑该找谁，如何分享数据报告，如何批注、评论等。</p><h4 id="功能强大和上手门槛">功能强大和上手门槛</h4><p>有些数据产品，功能多，给高级用户（Power User）很大的可操作能力，但往往会有高上手门槛的副作用。一个没有经验的用户，一开始使用产生的价值可能只能达到50分，但经过一段时间的学习，有些用户是可以做到120分的。</p><p>还有些数据产品通过一定的功能削减，来降低上手门槛，让一个没有经验的用户就可以做到80分，但高级用户的能力会受限，因为产品的能力最多也就90分。</p><p>如何权衡强大的功能和很低的上手门槛，解决新手和高手之间不同的诉求，是值得深入思考的。</p><h3 id="两种模式">两种模式</h3><h4 id="私有化部署on-premises">私有化部署（On-premises）</h4><p>数据产品一般是要连接或者采集企业的各种数据，很多企业不希望自己的数据出去，要求采用传统的私有化部署模式。</p><p>这种模式，对数据产品而言，在产品的基本能力之外，要有能力连接企业的其他系统，比如企业的用户账号系统，要有能力嵌入到企业的内部系统，如企业的门户系统（Portal）。总结起来就是<strong>开放和集成</strong>的能力。</p><p>另外要降低后期运维服务的人力成本，产品要足够稳定，要能自动化部署，要有完善的运维工具来提高问题定位和解决效率，总结起来就是<strong>稳定和运维</strong>的能力。</p><h4 id="云服务saas">云服务（SaaS）</h4><p>云服务让数据产品可以以很低的成本服务企业客户，按服务、按量收费的模式也能大大降低企业使用产品的开销。</p><p>产品的更新或问题解决能以更快的节奏给到企业客户，私有化部署可能带来的碎片版本，隔几年憋大版本重新收费的痛苦变得不复存在。</p><p>这种模式会对数据产品带来哪些挑战？</p><p>首先是生态的能力，这类企业的业务很大可能也已经在云上，那么如何去连接云上数据源的数据，甚至连接企业在云上其他 SaaS 服务的数据，会是不可或缺的能力。</p><p>其次，云服务面对的客户会更广，分类会更细，可能存在大量的小微企业。那么产品在使用门槛方面需要尽可能的降低。输出业务场景化的分析模版、或者提供基于领域的解决方案，会是一个途径。</p><p>第三，云服务的另一个优势在于可以平台化，虽然逻辑上客户之间是不可见的，但物理上是在同一个平台的，那么是否让不同客户能够分享甚至交换数据？是否要扩充、集成其他服务，比如提供云上数仓服务，甚至大数据基础服务？需要做抉择。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;http://blog.zhengdong.me/2019/01/07/speaking-of-a-data-team/&quot;&gt;上篇&lt;/a&gt;文章以一个数据团队发展的视角，总结了数据团队要做的事。当然，一些企业业务复杂起来之后，数据团队的职能也会发生分工，负责基础数据建设的团队，将数据集成、治理、资产管理、质量管控等工具及规范做掉，同时构建数据仓库的公共层并对上游业务以产品化和服务化的形式提供支持，现在比较热的「数据中台」概念就是指这块事情，和负责业务数据建设的团队，基于公共层数据，直接对接业务，让数据产品化、智能化，赋能业务发展。&lt;/p&gt;
&lt;h2 id=&quot;数据产品的四个层次&quot;&gt;数据产品的四个层次&lt;/h2&gt;
&lt;p&gt;这篇文章，主要想聊下数据产品，在我的理解里面，数据产品可以分为以下四个层次。&lt;/p&gt;
&lt;p&gt;首先是通用的数据分析及可视化工具，能够连接各种数据，解决分析师、运营等岗位人员查看和分析业务数据的需求，如进行数据的多维分析，数据报告的制作等工作。&lt;/p&gt;
&lt;p&gt;其次是场景化的数据分析产品，通用工具只解决了获取和分析数据的需求，但其实很难要求每个岗位都有好的数据分析能力，知道怎么用数据、怎么用好数据，知道数据的价值。场景化数据产品指的是用分析师沉淀下来的分析思路或分析模型来组织和展示数据，降低数据分析的门槛，提高数据化运营的效率。比如固化 ”AARRR“ 分析模型的用户分析和流量分析产品、活动大促的专题分析产品，面向业务场景的实时数据大屏产品等。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>从一个数据团队的说起</title>
    <link href="http://blog.zhengdong.me/2019/01/07/speaking-of-a-data-team/"/>
    <id>http://blog.zhengdong.me/2019/01/07/speaking-of-a-data-team/</id>
    <published>2019-01-07T13:42:33.000Z</published>
    <updated>2020-11-28T10:52:32.836Z</updated>
    
    <content type="html"><![CDATA[<p>大数据时代，在有庞大自有数据的企业，作为一个承担数据体系建设责任的数据团队要从哪些事情开始做起？</p><p>一开始，数据的需求很多都是企业的领导者要快速了解公司的业务情况，比如销售、财务、研发环节的一些统计指标。</p><p>于是数据团队开始熟悉企业的各种数据，把各种不同数据源的数据汇集到大数据技术栈：把业务数据库的数据同步出来，把在线系统的日志收集起来，把用户在产品各端的行为记录采集起来。接着，基于大数据技术栈，针对性做数据清洗、数据统计，然后将数据展现出来给领导者。</p><p>几个几十个指标这么做问题不大，但数据需求很快膨胀了起来，指标需求增长到好几百，数据团队开始疲于奔命响应业务方繁杂多变的需求。每个指标都要从原始数据算起，重复工作很多，加上都是独立做计算，同类指标口径歧义的问题也越来越严重。同时，快速增长的计算任务，带来任务产出稳定性、及时性的大幅下降。数据团队同时面临开发人力的不足、数据产出的不稳定以及业务方的频繁不满。</p><p>团队思考再三，为了解决困境，决定从以下两件事情做起。</p><p>第一是建立数据研发的系统，解决任务开发、调度、运维、质量保障方面的问题，把数据开发和数据产出管起来。</p><p>第二是建立企业的数据仓库，通过对企业业务和数据的调研、梳理，将企业各个业务领域的数据规整起来。通过定义一系列设计规范，完成数仓模型的设计，接着，基于数仓模型实施数据开发。</p><p><strong>数据仓库建设，是一个企业数据体系建设过程中很关键的一项工作，也是工作量巨大的一项工作。</strong></p><p>数据仓库建设过程中，产生的标准规范、表结构、任务依赖、存储计算资源、业务用途等信息，需要统一管理起来，如通过数据地图，让数据可见，而不是在一行行代码一个个计算任务里；通过血缘追溯，管控数据的依赖关系，数据的质量保障和问题跟踪能有据可依；数据还可以被从企业数据资产的角度来看待，来盘点。</p><p>有了数据仓库，有了不断丰满的业务指标体系，数据团队的工作变得规范、高效起来，团队也步入正轨。这个时候，新的问题出现了，企业业务高层领导者开始质疑：数据团队这么多人，做了这么久，怎么没看到什么产出，没看到对业务有什么实在价值？就做做数据报表需要这么多人？</p><p><strong>数据团队的价值在哪里，是整个团队面临的又一个大问题。</strong></p><p>团队开始思考，如何让数据产生价值。有几个想法大家越来越确定，</p><p>数据要产生价值，不是收集尽可能多的数据然后躺在那里，也不是开发尽可能多的指标然后展示在那里，而是要被用起来，被“活”用起来。</p><p>我们不能假定用户都会知道数据的好处，而是要降低用户使用数据的门槛，让用户知道怎么用数据、怎么用好数据，知道数据的价值。</p><p>一个个数据报告是静态的，但分析的理念和框架是动态的，是可行动的，通过提炼分析框架进行数据泛化形成数据产品，如 “AARRR” 模型的用户分析产品，如针对大促的全流程电商运营分析产品，才能让数据被真正用起来。</p><p>于是团队开始基于业务现状、目标来研发数据分析产品。在过程中，积累了不少心得：</p><ul><li>数据产品要聚焦业务场景</li><li>数据产品也要重视用户体验</li><li>数据产品要打通分析、行动，形成闭环</li></ul><p>有了数据产品，用户可以以很低的门槛使用数据，用数据做决策。接下来，数据团队面临的挑战又是什么呢？</p><p>挖掘数据价值，让数据不仅能通过分析框架来指导业务，还可以直接赋能业务，让基于数据洞察做业务创新变得可能。</p><p>团队通过用户画像做精准营销，做千人千面，通过基于行为的用户分类做用户促活、做流失用户挽回，通过销量预测做商品补货、做商品调拨 ……</p><p><strong>从数据分析到数据洞察，从业务描述、业务诊断到业务预测、决策支持。</strong></p><p>最后，总结下数据团队都做了哪些事情：</p><ul><li>数据采集和集成</li><li>数仓规划和建模开发</li><li>数据治理和数据资产管理</li><li>数据产品和服务</li><li>数据挖掘和算法赋能</li></ul><hr /><p>时下，很多大数据厂商不管是提供基础设施的，还是提供 PaaS 平台的，又或是提供数据应用的，都喜欢说自己是大数据整体解决方案提供商。回看这个数据团队所做的事情，这些厂商要做到什么程度才能称之为整体解决方案？才能从工具层面解放这个数据团队，让其聚焦到业务上，做产出最大的事情？</p><p>最基础的是覆盖技术栈广、性能高、且稳定的数据基础设施，满足数据离线/实时计算、存储、查询等需求。</p><p>然后是完备的数据开发工具支持，高效解决数据集成、数据开发、任务依赖管理等工作，以及完善的离线/实时任务监控、运维工具。</p><p>第三，配合数据开发工具，要能形成整合统一的元数据中心，解决数据治理问题，如数据的全链路血缘追溯、数据质量的监控保障等。另外，针对数据仓库建设，要从工具和标准规范层面打通数仓规划、模型设计、开发、测试等流程，降低数仓建设门槛。最后，能提供数据管理的门户，让从业务视角去管理企业的数据资产变得可能。</p><p>第四是通用和场景化的数据分析产品及服务，如可视化BI产品、应用/用户分析产品、营销监测产品、A/B试验产品、数据查询服务、用户画像存储和查询服务等，让数据团队不用花费大量时间去造轮子。</p><p>第五是机器学习算法建模、调试等工具支持，降低算法模型开发的上手难度，驱动数据团队基于数据智能的业务创新实践。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;大数据时代，在有庞大自有数据的企业，作为一个承担数据体系建设责任的数据团队要从哪些事情开始做起？&lt;/p&gt;
&lt;p&gt;一开始，数据的需求很多都是企业的领导者要快速了解公司的业务情况，比如销售、财务、研发环节的一些统计指标。&lt;/p&gt;
&lt;p&gt;于是数据团队开始熟悉企业的各种数据，把各种不同数据源的数据汇集到大数据技术栈：把业务数据库的数据同步出来，把在线系统的日志收集起来，把用户在产品各端的行为记录采集起来。接着，基于大数据技术栈，针对性做数据清洗、数据统计，然后将数据展现出来给领导者。&lt;/p&gt;
&lt;p&gt;几个几十个指标这么做问题不大，但数据需求很快膨胀了起来，指标需求增长到好几百，数据团队开始疲于奔命响应业务方繁杂多变的需求。每个指标都要从原始数据算起，重复工作很多，加上都是独立做计算，同类指标口径歧义的问题也越来越严重。同时，快速增长的计算任务，带来任务产出稳定性、及时性的大幅下降。数据团队同时面临开发人力的不足、数据产出的不稳定以及业务方的频繁不满。&lt;/p&gt;
&lt;p&gt;团队思考再三，为了解决困境，决定从以下两件事情做起。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关于大数据变现的一些思考（下）</title>
    <link href="http://blog.zhengdong.me/2018/10/28/ways-to-profit-from-the-bigdata-on-data/"/>
    <id>http://blog.zhengdong.me/2018/10/28/ways-to-profit-from-the-bigdata-on-data/</id>
    <published>2018-10-28T12:30:33.000Z</published>
    <updated>2020-11-28T10:52:32.834Z</updated>
    
    <content type="html"><![CDATA[<p>上篇从数据技术的角度谈了自己对大数据变现的一些思考，这篇继续，从企业的数据资产角度入手，谈谈变现的方式。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><p>数据资产变现是指企业通过自身拥有的数据进行的商业化变现。我始终认为数据已经是新的生产力，企业应该把最大的资源、最全的数据，首先用于自身，让数据驱动业务发展。接下来才是去想如何做商业化变现，不能本末倒置，当然，核心业务就是数据变现的企业另说。</p><h2 id="在线广告">在线广告</h2><p>从门户网站开始，在线广告模式的变现就是很多互联网公司收入的主要来源，现如今，全球和国内广告收入的一二名都是互联网公司。</p><p>最常见有两种广告方式，一个是品牌（合约）广告，一个是效果广告。</p><p>品牌广告是从传统的线下广告、电视广告发展而来的，按曝光量来计费，客户的核心诉求是在固定投入的前提下最大化对目标用户的曝光量。效果广告则是按效果计费，客户的核心诉求是以较低的转化成本达成较高的转化规模。比如我们经常看到的视频贴片、门户banner、App开屏等广告多属于品牌广告方式，而通用搜索、电商搜索、信息流等广告采用效果广告方式居多，当然也有融合的，比如信息流广告也存在一部分品牌广告。</p><p>有流量就可以做广告，但品牌广告方式下，如何在满足曝光量的同时，定位到客户的目标用户，最大化利用自身流量，效果广告方式下，如何在提高客户转化效果的同时，最大化自身广告收入，都需要数据来支撑。</p><p>这里引申出广告变现模式的两大前提：用户体量和清晰且有价值的目标人群。</p><p>要做这个生意之前，首先是要对自己的用户体量有认识，体量太小自己做广告平台投入产出比太低。其次是要能对自己的用户有深度洞察，数据不好连自己用户的画像都做的不准，这门生意也做不好，比如明明自己的用户大多是中小学生，却接了汽车厂商的广告，自己的用户大多是中年男性，却接了麦当劳的广告。</p><p>这也是为什么在线广告市场可以算是互联网大厂的自留地，既有大的用户量，又有沉淀下来精准的用户数据。那如果有精准、全面的数据，却没有流量，还有什么方式做变现？</p><h2 id="营销优化">营销优化</h2><p>广告营销市场的规模非常大，企业在营销方面的预算，往往比采购技术产品大很多，这也是很多厂商依仗着数据往营销优化市场去挤的原因，能帮客户提升营销效果、降低营销成本，是实打实能打动客户的，只要效果够好，议价能力会很强。</p><p>前面数据技术变现部分提到过一种“羊毛出在猪身上狗来买单“的变现模式，很多就发生在数据驱动营销优化这门生意上。</p><blockquote><p>通过免费模式吸引客户，在服务客户的同时，沉淀客户数据并整合，最后，通过这些数据，从别的客户那里赚钱。</p></blockquote><p>业内有几种做法：</p><p>基于自身拥有的用户及行为数据，建立用户ID和标签体系，通过输出用户画像信息，以三方 DMP 的名义接入 DSP，来获取分成，一些中小互联网企业会这么干。</p><p>还有些企业直接贡献自己的数据，和广告主合作建设广告主的一方 DMP 来变现，甚至有的还会帮客户方做实施，除了贡献数据外，帮企业建立一整套定制的如站内推荐、用户画像、商业分析、营销效果评估、可视化报告等系统，不过这个更多属于数据技术变现范畴了。通常这些企业的数据质量不够好，价值不大，才愿意直接贡献出来。</p><p>第三种方式，对一些比较在意数据安全，不愿意直接对外输出的企业，可以采用碰数据的形式：通过数据开放服务，广告主上传用户列表，企业在自己的 DMP 中进行匹配，输出用户所对应的标签信息，来进行数据变现。</p><p>当然，这种“开放”做多了，数据等于还是出去了，所以很多企业，会把后面的用户触达也给做了，这样广告主是拿不到用户信息的，只能通过用户标签选择用户群，或是通过 lookalike 做用户放大，不少中大型互联网企业提供这类服务。</p><p>这个模式能做好，自身数据的全面和准确很重要，比如碰数据的时候，能匹配到广告主给的用户的比例太小，匹配到的用户标签不准、标签的商业价值很低等，是做不出好的效果的，也做不长久。</p><p>虽然大数据技术大大促进了如今营销业的发展， 但它其实是个老产业，盘子大，做的企业很多且鱼龙混杂，水挺深。</p><h2 id="saas-的另一种出路">SaaS 的另一种出路</h2><p>从厂商的角度看，产品通过 SaaS 的形式提供服务，能大规模部署，高效运维，也能持续迭代升级，迅速修复问题，还能防止买断式模式带来的尾款、服务费等不能收回的风险。对客户而言，在线试用、在线支付、按使用时长或资源付费等能大大降低接入和使用成本。</p><p>但从数据的角度看，产品 SaaS 化还存在另一种潜力，能大大提升整个产品的价值和变现能力，那就是：<strong>通过 SaaS 服务触达上下游，沉淀全网数据，再通过数据服务来变现。</strong></p><p>数据变现部分提到过数据产品免费提供服务、通过数据变现的例子：</p><blockquote><p>拿提供移动应用分析产品的厂商举例，一开始免费接入客户，不断提升产品的体验和能力，强化在市场上的竞争优势，接下来，通过数据榜单、行业会议、线上线下活动等市场行为不断强化客户的认知，比如覆盖多少应用、多少设备、多少行业、数据有多准多全等，最后，依仗着全网的数据，在金融、房地产、零售等行业赚钱，比如提供基于精准用户定向的跨应用营销，个人信用、收入、兴趣等的人群洞察，地理位置消费能力热图，手机品牌保有量地区分布、人群品牌偏好等服务。</p></blockquote><p>其实不仅是数据类产品，这也可以是其它各类 SaaS 产品的另一种出路。比如面向个人的线上免费记账产品，可以包装个性化理财服务进行数据变现；连接用户和商户的客服产品，可以包装精准用户定向的触达服务进行数据变现。</p><p>当然，所有这些的前提是，得能连接上下游，得有全网或全行业的用户覆盖。</p><h2 id="垄断数据的魅力">垄断数据的魅力</h2><p>这里首先当提电商平台型企业都有的生意参谋类产品。购买了这个数据产品，商户除了能看到自己商品的流量、交易、财务、物流等分析报告外，还能和同品类、同行业的数据进行对比，能获取自己用户的画像数据，更好的提升服务和制定决策，能 …</p><p>而这些东西，都是要付费的，往往面对的还是按功能区分的阶梯定价模式。通过对垄断数据进行产品化，进而定价售卖，是门很赚钱的生意，关键是除了所在平台外，没有谁能提供这些服务。而之所以当年能产生这个变现模式，就是因为电商平台在自身业务的经营中，数据变得越来越重要，并且通过数据产品化产生了很大价值，对外输出是顺便的事，就赚了大钱。</p><p>好做的生意总是门槛高的，首先得有<strong>全面的、可信度高的、聚焦行业的垄断性数据</strong>。这种模式，大家还能想到其他厂商么？</p><h2 id="数据交易">数据交易</h2><p>数据交易，主要是技术投入少、水平不高或商业化能力受限，但有大量数据（全网或覆盖单个行业）的企业，常采用的数据变现方式。表现出来的就是一锤子买卖和白菜价。</p><p>当然，有些“垄断”数据的企业，拿国内运营商举个例子，可能会通过差异化的数据包来解决一锤子买卖的问题，如对特定地区用户群体的出行轨迹、主流 App 的使用频次分布等数据单独售卖，也会寻求和其他企业通过数据层面的合作去变现，至于做了什么效果如何，就不知道了。反正经常经历或听说某些运营商劫持用户流量投广告赚钱，真是没出息。</p><p>其实对于运营商而言，抓着全网的数据，理应能做垄断数据的生意，也许是因为隐私保护政策的原因做不起来吧，但我想更大的原因在于前面一节我提到过的：</p><blockquote><p>而之所以当年能产生这个变现模式，就是因为电商平台在自身业务的经营中，数据变得越来越重要，并且通过数据产品化产生了很大价值 。。。</p></blockquote><p>数据交易之外，数据报告也是一种变现方式。拥有的数据企业可以通过自己做，或和行业咨询公司合作，由专业人士对数据加以分析、挖掘、<del>美化</del>，形成特定领域的行业分析、市场研究、销售状况等咨询报告面向社会销售加以变现，效果如何很大程度取决于出品方的市场口碑和公信力。</p><h2 id="数据合作">数据合作</h2><p>企业或多或少都拥有数据，一个企业的数据可能会对其他企业的业务发展有用，也可能觉得其他企业的某些数据对自己的业务会有帮助，这个时候，数据合作就成为一个诉求，也是数据作为一种资产，必然会面临的。</p><p>数据合作，首先要保护企业的数据知识产权，保护用户和企业的隐私，其次，需要能融合、匹配多个企业的数据，否则合作也就失去了价值。</p><p>业内有种合作模式，通过中立第三方实体作为数据合作平台，当然，这个第三方需要由法律协议来约束，也要接受审计。</p><p>首先企业双方将数据上传至第三方实体，上传过程中关键数据字段可以进行脱敏。接下来彼此的研发人员就可以通过数据合作平台提供的工具来进行数据、算法等的开发。开发人员查询、调试过程的数据都是经过限制条数、动态采样以及脱敏的，合作平台会从技术层面来保证安全。当基于企业需求的算法模型开发完成上线后，才会真正运行在平台的全量数据上，最终企业双方都获取满足自身需求的数据产出物，而双方的明细数据在整个合作过程都是彼此保密的。</p><p>这种合作模式下，保险公司可以和车载系统服务商进行数据合作，通过对用户的行车数据进行分析，通过算法模型做到千人千面的差异化车险定价；信用借贷公司可以和电商企业进行数据合作，实现差异化授信额度的制定和风险控制。</p><p>数据合作模式要跑通，需要具备公信力的第三方，合作平台也要能从技术上保证彼此明细数据的不可见，还要提供便捷的开发套件供数据开发，算法调试使用，有一定的技术门槛。最后，数据合作模式下，如何进行定价也是一个问题，毕竟在最终验证业务价值前，企业双方对彼此数据价值的认知可能是不一致的。</p><h2 id="写在最后">写在最后</h2><p>数据资产变现部分写到的几种方式，是目前比较多在用的，也或多或少验证可行。数据资产变现从大的角度来说还有很多，比如在医疗领域给医学发展带来很多可能，助力金融等行业的变革，推动人机对话，自动驾驶，智能家居等技术的从无到有到大规模普及等等。</p><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>本文仅代表个人观点。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;上篇从数据技术的角度谈了自己对大数据变现的一些思考，这篇继续，从企业的数据资产角度入手，谈谈变现的方式。&lt;a href=&quot;#fn1&quot; class=&quot;footnote-ref&quot; id=&quot;fnref1&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;数据资产变现是指企业通过自身拥有的数据进行的商业化变现。我始终认为数据已经是新的生产力，企业应该把最大的资源、最全的数据，首先用于自身，让数据驱动业务发展。接下来才是去想如何做商业化变现，不能本末倒置，当然，核心业务就是数据变现的企业另说。&lt;/p&gt;
&lt;h2 id=&quot;在线广告&quot;&gt;在线广告&lt;/h2&gt;
&lt;p&gt;从门户网站开始，在线广告模式的变现就是很多互联网公司收入的主要来源，现如今，全球和国内广告收入的一二名都是互联网公司。&lt;/p&gt;
&lt;p&gt;最常见有两种广告方式，一个是品牌（合约）广告，一个是效果广告。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关于大数据变现的一些思考（上）</title>
    <link href="http://blog.zhengdong.me/2018/10/27/ways-to-profit-from-the-bigdata-on-tech/"/>
    <id>http://blog.zhengdong.me/2018/10/27/ways-to-profit-from-the-bigdata-on-tech/</id>
    <published>2018-10-27T12:55:57.000Z</published>
    <updated>2020-11-28T10:52:32.834Z</updated>
    
    <content type="html"><![CDATA[<p>年初（2018）接受 DTalk 社区访谈 ，对“大多数企业怎样把大数据落地变现？”这个问题，我当时是这么回答的：</p><blockquote><p>我理解的大数据落地变现有两大模式，一种是基于大数据技术，另一种是基于已有的数据资产。大体有如下几种方式：</p><ol type="1"><li>输出平台型技术能力，通过给企业建设大数据平台来变现；</li><li>输出大数据处理技术和应用产品，比如把企业内部的BI、应用/用户分析、营销监测、数仓应用等产品进行商业化输出或者通过数据建模咨询和实施来变现。</li><li>基于数据的闭环服务变现，如营销方向的广告精准推送、金融领域的风控服务等。</li><li>咨询类的数据报告，针对不同领域提供对客户有价值的分析及数据报告等。</li><li>数据交易。</li></ol></blockquote><p>最近，在数据技术变现和数据资产变现这两个方向，我又深入梳理了自己的认识，并将我的思考写了出来，这篇是数据技术变现部分。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><h2 id="从-bi-产品开始">从 BI 产品开始</h2><p>BI 产品在大数据这个概念出来之前，已经是蛮成熟的品类。简单说来，就是能连接和有效整合企业内部各个数据源的数据，通过强大灵活的分析能力，以丰富的可视化形式来展现数据，帮助企业进行业务经营决策。</p><p>之前的主流厂商主要是国外的大型企业服务公司，产品往往会比较重，也会和自身的其他产品，如 OLAP 工具、CRM 等产品整合，整体使用门槛高，且需要不小的团队来维护。后来，很多新兴企业用敏捷 BI 这个品类，大大降低了产品的接入成本和使用难度，价格也大幅度低于以前，市场份额越来越大。因为产品比较通用，并且内部业务都会有需求，这也成为一些互联网企业数据技术团队内外输出数据产品的第一站。</p><p>下面几种商业模式使用的比较多：</p><p>第一种是 SaaS 模式，这个模式很轻，可以以较低的成本服务大量客户，所以收费比较低，一般按年和账号数来计费。但因为要连接企业的数据，尤其大企业，往往不能接受这个模式，不过公有云厂商提供这个服务反倒有很大优势， 因为企业用户的数据已经在云上。</p><p>接下来是私有化模式，产品部署到企业自己的环境中，说到底就是卖软件，硬件是客户的。有两种收费模式，买断制和订阅制。从现在软件售卖的市场看，订阅制是趋势。买断制起始价格高，但要生意持续，往往需要周期性憋大招升级大版本让客户升级，再次售卖。而订阅制价格相对低一些，对企业来说，因为按年持续有收入，业务会更健康，也不用花力气做大版本创收，持续改进产品就好，另外，还能大大减少维护多个遗留版本带来的研发投入。</p><p>最后一种是项目制，不仅仅是卖软件产品，而是解决企业客户的问题，比如报表体系建设、业务数据门户等，除了涉及通用产品外，还可能会有数据 ETL、数仓建模、报表实施等交付工作。</p><p>BI 产品商业化，虽然属于通过数据技术变现，但 BI 产品和业务离得很近，客户选择时，往往考虑业务多于技术，如何解决不同行业客户多样的问题，还能坚守产品的通用性，不陷入企业定制开发的漩涡；如何在价格透明甚至低价格战的竞争格局中去占领市场份额，去盈利，会是比较重要需要解决的问题。</p><h2 id="数据基础设施">数据基础设施</h2><p>数据基础设施，一开始是从解决业务问题的 OLTP 数据库开始，随着数据越来越被重视，数据仓库的概念被提了出来。传统的数据库厂商在 OLTP 产品之外，投入很多资源在 OLAP 产品的研发、推广上，同时，市场出现了不少 MPP 厂商，也占据了一席之地。然后大数据时代来了，随着大数据的概念、实践从互联网公司走向各个行业，大数据平台这个品类开始逐步替代传统数据库、MPP 厂商们。</p><p>大数据平台通常提供如下能力：</p><ul><li>数据集成 提供数据采集、传输/同步能力，能将各个环节、数据源的数据同步到大数据平台，统一存储。</li><li>开发平台 提供统一的开发环境，满足开发人员进行数据任务的开发、测试及运维等工作。</li><li>任务调度 提供任务托管和调度能力、并通过计算引擎完成任务的执行，大数据栈的很多技术会包含在这里。</li><li>数据管理 提供元数据管理、存储和成本管理、数据质量管理等能力。</li></ul><p>现在机器学习的概念很火，很多大数据平台也提供了机器学习方面的开发、建模、计算等支持。</p><p>公有云厂商和企业服务厂商采用了两种不同的商业模式：</p><p>第一种是 EMR 服务，公有云厂商大多都会提供，也是云里比较赚钱的业务。这个模式下，用户不需要去操心如何去选型、准备机器、搭建部署整个大数据平台，直接使用厂商提供的 EMR 集群，按需创建即可，计算结束可以很方便的释放，带来成本的降低。这个模式有很大的前提，就是企业的数据已经在云上，即通过公有云的基础设施服务来带大数据基础设施服务的售卖。</p><p>第二种是私有化部署模式，目前市面上的主流厂商大多都支持这个模式，包括很多公有云服务厂商，面对的客户主要是中大型企业。从竞争来看，国内外厂商很多，竞争比较激烈，不过这种模式一两家厂商很难做到垄断，而且不同厂商对市场、目标客户也或多或少有不同的定位，还在前赴后继的进入。</p><p>现在也有一些厂商在垂直领域，比如数据集成、数据仓库等方面提供服务，但能看到，很多做着做着，平台的一些能力都会逐渐加上来，变成大数据全栈服务提供商。这引申出来第一个问题，就是厂商同质化严重，因为基础组件大多基于开源，大家都是站在巨人的肩膀上。</p><p>另外，私有化模式的采购周期往往很长，因为涉及比较大的采购费用，厂商在平台功能、服务能力、性能指标、客户案例等方面，会面对客户很多挑战。</p><p>还有就是 lock in 的问题，大型的交付往往会对客户形成一定的 lock in，即一旦企业客户的业务在平台跑起来，换厂商的迁移成本非常高，所以，通过对既有客户的服务，挖掘客户更多需求，赚更多收入，是非常重要的。对客户而言，也会在意这个问题，这个时候，自研或基于开源的选择会对客户产生影响，基于开源，即使厂商提供不了服务，客户自己也能比较容易招人，继续维护，不像自研的，离了厂商什么都做不了，会成为一种有竞争优势的销售说辞。</p><p>第三种是解决方案模式，可以是技术咨询、也可以是工具+技术咨询、工具+项目实施、或是综合的行业解决方案，比如金融、政务、工业等的大数据解决方案。这块后面还会提到。</p><h2 id="数据应用产品">数据应用产品</h2><p>还在 web 主导的互联网时代，专注流量分析的 web analytics 产品已经很多，往往还是免费模式。移动互联网起来之后，市场上出现不少移动应用分析产品，以开发者工具的定位免费提供服务，很快发展了起来，除此之外，还有营销和广告监测、用户行为分析、A/B 测试、用户画像等解决特定领域问题的数据产品。</p><p>数据应用产品是指以标准产品的形式，利用数据，去解决客户垂直领域或特定场景下的问题。比如用户行为分析产品，就将数据采集、传输、计算、展现等工作打包起来，作为黑盒，客户不再需要关心技术细节，接入后，只需要看数据做决策就好。</p><p>这些产品大多是通过 SaaS 模式来提供服务，有以下几种变现方式：</p><p>第一种是免费模式，通过咨询服务变现。早先很多做移动分析的 SaaS 厂商，会提供基于客户数据的数据挖掘、用户画像等付费服务。</p><p>第二种是直接收费模式。一般按照数据量或账号数收费，还有按照功能集合进行分层定价。当然，这个模式的厂商也在寻求咨询服务方面的收入，比如搭配着产品，去做时下很火的增长黑客培训，或是直接帮助客户做业务增长的咨询和落地服务。</p><p>最后是“羊毛出在猪身上狗来买单“模式。通过免费模式吸引客户，在服务客户的同时，沉淀客户数据并整合，最后，通过这些数据，从别的客户那里赚钱。拿提供移动应用分析产品的厂商举例，一开始免费接入客户，不断提升产品的体验和能力，强化在市场上的竞争优势，接下来，通过数据榜单、行业会议、线上线下活动等市场行为不断强化客户的认知，比如覆盖多少应用、多少设备、多少行业、数据有多准多全等，最后，依仗着全网的数据，在金融、房地产、零售等行业赚钱，比如提供基于精准用户定向的跨应用营销，个人信用、收入、兴趣等的人群洞察，地理位置消费能力热图，手机品牌保有量地区分布、人群品牌偏好等服务。</p><p>数据应用产品的商业化过程会碰到些问题，一个是数据安全问题，很多客户尤其是大的企业不愿意数据在云上，导致这些产品的客户群往往是初创或中小企业，进入大企业很难。一些厂商会提供客户侧私有化部署的支持来吸引大企业，和前面提到的 BI 产品私有化模式一样，也会碰到部署实施、售后服务、客户定制需求等问题。</p><p>另一个问题是采购 vs. 自研的矛盾。拿用户行为分析产品举例，初创企业一开始还着立于验证商业模式，采用第三方云服务阻力不大，但随着业务的增长，尤其当数据被重视起来后，需要去建设自己企业的数据体系，第三方服务经常会被企业自研的产品所取代。放眼看过去，几乎每一个中大型互联网企业，都有自研的数据埋点、流量分析、用户分析、营销分析等产品，一些大企业内部还不止一套，可见自研的吸引有多大。</p><h2 id="大数据解决方案">大数据解决方案</h2><p>在 BI 产品部分，提到过项目制的模式，BI 产品在大数据概念流行前已经很成熟，很多企业已经被教育的认为合作模式就应该是这个样子的。所以很多时候，会在产品的基础上，根据客户的需求，把业务咨询、数据体系建设、数仓建模、报表实施等工作也做掉，以项目的方式交付给客户。</p><p>对于很多企业客户而言，尤其是传统行业的客户，采购厂商的数据产品是为了解决问题，它不希望面对一个个产品或是产品功能集合来选择，而是会看有没有同行业的企业在用，是怎么用的，对企业面临的需求有没有成熟的解决方案等。</p><p>业务咨询和数据运营指导、数据体系建设和数仓建模、定制化数据产品等企业服务，是很多解决方案提供商做了很久的生意。随着大数据、AI 的流行，企业的需求也越来越多，比如推荐系统、机器学习算法模型、用户画像体系等的建设。以上种种需求，是很多大数据平台通过解决方案在企业落地的切入点。</p><p>时下有两个大的概念：</p><p>一是企业的数据中台建设，主要是互联网企业在推，用互联网企业建设自己全域数据中台的理念、经验，去帮助企业建设自己的数据中台。二是行业的大数据解决方案，比如智慧城市、政务大数据、工业大数据、金融大数据等。这两块可以打包进去很多东西，能大大提高整个项目的报价，以及有比较大的持续合作的可能，客户价值更高。</p><p>做解决方案类项目实施虽然能提高客单价，但很重，而且这个行业一直是企业服务巨头的自留地（有些项目厂商驻场在一家银行能做十多年持续赚客户钱）。大数据技术的发展给了互联网厂商进入这个市场的机会，从技术积累到品牌形象都有竞争优势，不输传统企业服务厂商。当然，互联网公司深深的 to C 基因，一开始内心往往是排斥的，要给每个客户做，还要理解客户业务，完全不能 scale 呀。但慢慢大家会认识到， 在大数据企业服务市场，做标杆大客，沉淀解决方案，然后行业内复制也是一种有效的增长模式。</p><p>是不是做大数据解决方案就只是为了提高客单价，从单个客户赚更多钱？</p><p>我认为不全是，从客户角度上来看，大数据解决方案是面对需求的，比卖产品 feature 更能吸引客户签单。从厂商角度看，<strong>解决方案能打破客户采购的对标价格体系，通过创造差异化来提高议价能力。</strong>在成熟行业做标品生意，竞品之间的价格基本上是透明的，企业客户在采购过程中的议价能力非常强，也容易碰到一些低端厂商挑起的价格战。但解决方案模式，每家提供的服务、价格都是不一样的。</p><p>最后，大数据解决方案这个商业模式要做好，会碰到非常多的问题。比如如何积累团队的业务咨询能力和行业知识，如何处理人力大幅增加带来的薪酬和管理成本问题，如何建立高效且有能力的项目实施交付团队，是否需要合作伙伴一起做落地以及如何选择，如何解决合作伙伴间配合的问题，如何维护客户关系，如何控制整体成本，如何从项目中沉淀可复制的解决方案，而不是做一个算一个沦为外包服务商，如何保证核心产品的通用性，防止大客户的定制需求拖死产品研发团队等等坑都是要趟过的。</p><p>不是每个企业都适合做这个事，要深入分析自己企业的能力、发展方向，不能看到别人这么做自己想都不想也这么做。</p><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>本文仅代表个人观点。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;年初（2018）接受 DTalk 社区访谈 ，对“大多数企业怎样把大数据落地变现？”这个问题，我当时是这么回答的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我理解的大数据落地变现有两大模式，一种是基于大数据技术，另一种是基于已有的数据资产。大体有如下几种方式：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;输出平台型技术能力，通过给企业建设大数据平台来变现；&lt;/li&gt;
&lt;li&gt;输出大数据处理技术和应用产品，比如把企业内部的BI、应用/用户分析、营销监测、数仓应用等产品进行商业化输出或者通过数据建模咨询和实施来变现。&lt;/li&gt;
&lt;li&gt;基于数据的闭环服务变现，如营销方向的广告精准推送、金融领域的风控服务等。&lt;/li&gt;
&lt;li&gt;咨询类的数据报告，针对不同领域提供对客户有价值的分析及数据报告等。&lt;/li&gt;
&lt;li&gt;数据交易。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;最近，在数据技术变现和数据资产变现这两个方向，我又深入梳理了自己的认识，并将我的思考写了出来，这篇是数据技术变现部分。&lt;a href=&quot;#fn1&quot; class=&quot;footnote-ref&quot; id=&quot;fnref1&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;从-bi-产品开始&quot;&gt;从 BI 产品开始&lt;/h2&gt;
&lt;p&gt;BI 产品在大数据这个概念出来之前，已经是蛮成熟的品类。简单说来，就是能连接和有效整合企业内部各个数据源的数据，通过强大灵活的分析能力，以丰富的可视化形式来展现数据，帮助企业进行业务经营决策。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关于数据采集和用户行为分析平台的一些问题</title>
    <link href="http://blog.zhengdong.me/2018/04/04/questions-on-data-collection-and-data-platform/"/>
    <id>http://blog.zhengdong.me/2018/04/04/questions-on-data-collection-and-data-platform/</id>
    <published>2018-04-04T12:48:27.000Z</published>
    <updated>2020-11-28T10:52:32.833Z</updated>
    
    <content type="html"><![CDATA[<p>最近要参加一个关于数据埋点和分析的线上讨论，这两天总结了对一些问题的思考。</p><h2 id="为什么企业需要一套完善的用户行为埋点和分析平台">为什么企业需要一套完善的用户行为埋点和分析平台？</h2><p>一个互联网产品从萌芽到发展壮大，离不开对用户行为的深度洞察。</p><p>产品初创期间，需要分析天使用户的行为来改进产品，甚至从用户行为中得到新的思路或发现来调整产品方向；产品 growth 过程，通过对用户行为的多角度（多维）分析、对用户群体的划分以及相应行为特征的分析和比较，来指导产品设计、运营活动，并对市场渠道效果进行评估。</p><p>配合上 A/B 试验平台，可以加速产品的迭代，更快得到用户的真实反馈。同时，这些数据沉淀下来，对业务的数据仓库建设、数据智能应用等方面也能起到促进作用，比如做实时推荐，需要能更快获得用户尽可能多且明细的行为数据；做用户分类、意愿预测等机器学习业务，需要清洗过的规范化、结构化的数据做 training。</p><p>要能做用户行为的分析，就需要有一套用户行为数据采集、传输、处理、分析的基础设施，而埋点和分析平台就是在做这件事。业界大多产品都是通过嵌入到多个终端的 SDK 来采集用户行为数据，而后续的传输、处理等过程对需求方是透明的，这样可以以很低的成本，把数据的采集、清洗、沉淀工作做掉，为企业节省成本，提升数据驱动的效率。</p><p>在分析平台上，用户的行为定义会通过特定 <code>Event</code> 来标识，比如 "buttonClick", "playMusic" 等。通常这些事件，是开发人员通过调用 SDK 提供的 API 来设置的，除了确定事件的名称外，还可以加入分析需要的自定义参数和取值，这个过程就是“埋点”工作。当然，还有一些工具/产品支持可视化埋点，这种方式不需要开发介入埋点，SDK 会自动去采集用户在各个终端上的行为。</p><h2 id="代码埋点可视化埋点和无埋点有哪些区别在使用过程中该如何选择">代码埋点、可视化埋点和无埋点有哪些区别，在使用过程中该如何选择？</h2><p>分析平台通常会提供各端的数据采集 SDK，代码埋点是产品开发者通过调用这些 SDK 提供的一些 API 来记录用户行为的方式，及俗称的“埋点”或者“打点”。</p><p>如 <code>trackEvent("buttonClick")</code></p><p>可视化埋点是指开发人员除集成采集 SDK 外，不需要额外去写埋点代码，而是由业务人员通过访问分析平台的 <code>圈选</code> 功能来“圈”出需要对用户行为进行捕捉的控件，并给出事件命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 SDK 按照圈选的配置自动进行用户行为数据的采集和发送。</p><p>无埋点是指开发人员集成采集 SDK 后，SDK 便直接开始捕捉和监测用户在应用里的所有行为，并全部发送到分析平台，不需要开发人员添加额外代码。在分析时，业务人员通过分析平台的圈选功能来选出自己关注的用户行为，并给出事件命名。之后便可以对特定用户行为（事件）进行多维分析了。</p><p>可视化埋点和无埋点比较像，都不需要开发人员手工加代码，也都需要业务人员进行所关注的用户行为的圈选。两者最大的不同是在用户终端的表现上，可视化埋点只采集业务人员关注的用户行为数据，而无埋点是会采集所有用户的行为数据，通常情况下数据量后者比前者大很多。</p><p>也正是由于无埋点默认采集所有用户行为数据，它能够做到事件的<code>回溯</code>分析，即在业务人员新定义（圈选）事件后，就能去分析这个事件在前面一两个月的数据情况，这也是可视化、代码埋点支持不了的。但带来的问题就是采集所有数据对应用的侵入会有些大，也会增大用户端采集的数据量。当然，可以通过一些策略，比如 Wi-Fi 下才发缓解这些问题。</p><p>无埋点和可视化埋点很大一个缺陷在于它们都是通过采集 SDK 去监测应用上控件的触发事件（用户对控件的操作），当产品 UI 在版本升级过程发生变动，或者产品做了大的改版，一些行为的“埋点”会发生丢失。如控件ID发生变化，而圈选的配置没变，导致数据采集不到；或者和业务的实际需要发生不一致的变动，比如圈选控件的作用发生了变化，但圈选配置没改；这些问题会导致对产品某些方面的分析出现差错，往往查起来还比较麻烦，在技术上完全解决也比较困难。</p><p>另外，可视化埋点和无埋点都针对的是客户端数据采集，一些用户行为数据在客户端是采集不到的，或者客户端采集的精准度不够，比如支付，因为支付成功的判断绝大多数场景都是在服务端做的，所以在客户端做支付行为的埋点，误差很大，这个时候就需要在服务端进行埋点。</p><p>我的建议是，在产品初期，产品形态还不太稳定、分析的复杂度还比较低的阶段，采用无埋点或者可视化埋点，更快去做埋点，否则频繁的产品改动，会让开发人员大量时间花在琐碎的埋点代码维护上面。产品进入稳定期后，尽量采用代码埋点方式，可以保证事件模型是稳定的，便于长期的数据监控、分析和数据沉淀。</p><h2 id="如何进行数据埋点方案及规范的定义以及后续怎么进行维护和管理">如何进行数据埋点方案及规范的定义，以及后续怎么进行维护和管理？</h2><p>一个互联网产品业务数据驱动的 workflow 往往是这样的：</p><ol type="1"><li>定义产品的阶段性目标；</li><li>规划和定义指标，包括产品、运营、市场的各项目标；</li><li>产品、运营等业务人员确定数据埋点需求；</li><li>开发人员进行埋点以及数据的上报等开发工作；</li><li>数据开发人员进行数据的清洗、宽表建设、指标计算等工作；</li><li>业务人员分析数据、发现产品问题或潜在机会；</li><li>继续下一阶段的产品、运营、市场等的改进工作。</li></ol><p>用户行为分析平台的目标就是将其中 4-6 阶段的工作变得简单和自动化，把开发人员解放出来去做更多对业务有价值的工作。而 1-3 部分的工作，看起来不复杂，基于业务现状去定义指标，排出埋点需求，和开发人员确认好就完成了。</p><p>但这块从实践上来看，很多企业或者业务都做的不够好。比如定义的事件数量迅速膨胀，一段时间后，团队可能大部分人都不知道某些埋点是做什么的，开发人员也不好删掉，就一直存在着，可能早已失去了业务价值；或者业务人员定义了埋点需求，但开发人员埋点做错了，彼此都没发现，导致分析过程出现错误解读；又或者上线了才发现埋点的参数或者位置不对，但又必须得等到下一次发版本才能解决。</p><p>这块有几件事情可以做：</p><ul><li>指标管理系统，用来维护指标依赖的数据表、字段以及计算方式，来统一开发、分析和解读过程的口径。</li><li>埋点管理系统，用来管理埋点的元数据，包括事件 <code>Event</code> 的命名、自定义字段含义和特定取值等规范定义，埋点在产品端的位置或触发场景，埋点工作流等，作为业务人员、开发者、分析师沟通的桥梁和基准。</li><li>埋点测试和校验系统，提供 debug 工具方便开发人员快速进行埋点调试，以及使用事件定义的规范要求，在线上对埋点数据进行校验，尽早发现不符合规范的数据，提高埋点工作的效率和准确性。</li></ul><h2 id="如何做好埋点工作和研发的协调和落地">如何做好埋点工作和研发的协调和落地？</h2><p>在实践中，很多开发人员不太愿意做“埋点”的工作，觉得很琐碎，而且随着产品的发展，包袱有时候会越来越大，维护的工作量不小。</p><p>要让埋点工作在研发比较好的落地，最能提升的地方还是在于如何简化开发人员的工作，包括开发成本和沟通成本。</p><p>采集 SDK 应该尽量简化 API，能自动做的就不要让开发人员来做，比如应用生命周期的检测、PageView 的采集、甚至对一些企业内部组件化框架的支持，尽可能减少开发人员接入分析平台需要添加的代码量。</p><p>有完善的埋点管理系统，这样研发端可以依据进行开发，减少“口口相传”带来的低效和返工，也能统一口径和进度流程。</p><p>有高效易用的埋点测试、校验系统，开发人员可以快速进行埋点 debug，提高开发效率，也能让业务方尽早介入需求校验，而不是等应用真正发布后才去校验，去发现问题。</p><p>当然，最好能和开发人员持续分享数据是如何促进业务的发展，让大家明白这些工作的价值，才能更重视，更认真对待这部份工作。</p><h2 id="埋点数据采集与企业数据资产建设怎样更好的合作">埋点数据采集与企业数据资产建设怎样更好的合作？</h2><p>用户行为分析平台在建设时，数据端会包含如下能力：</p><ul><li>数据接入，要支持客户端、Web、服务端等多终端的数据采集，如 iOS、Android、微信小程序等，以及各种数据源甚至三方服务的数据适配。</li><li>数据传输，在用户规模和数据规模增长过程中，要能保证数据传输服务的高可用、以及采集数据在传输过程的及时性。</li><li>数据建模/存储，要能实时的进行数据清洗、建模和存储落地。</li></ul><p>这些能力，在互联网业务的数据资产建设过程中，尤其是用户、流量、产品相关领域，能起到基础设施的作用。规范的数据采集，加上高效的传输、建模能力，是企业业务数据资产有效建设的前提。</p><p>建模后的数据，可以作为数据仓库底层（ODS 层）的宽表，和企业的其他业务数据整合，共同完善企业的数据资产建设。</p><p>另一方面，这些用户端的结构化数据，加上实时建模和开放的能力，和机器学习算法结合起来，无论是个性化推荐，还是精准营销，又或是银行、电商的风控，都可以发挥很大威力，为企业的智能驱动业务做好数据积累，扫清障碍。</p><p>企业在数据建设的过程中的产出，也可以扩充以 PaaS 提供服务的用户行为分析平台的能力，让企业在平台上可以做更多的事情，如 CRM、推送、实时推荐等。</p><p>拿 DMP （用户画像）建设举个例子，</p><p>企业在建设自己的 DMP 库的过程中，常常会从常规的人口属性等准静态类标签，以及像消费能力等从自身业务积累或三方合作得到的通用类标签入手。这些标签往往是泛业务的，针对具体业务而言，很多时候会需要用户画像标签更贴近业务，比如电商业务场景下的母婴用户、电子产品发烧友、化妆品品牌喜好用户等。这些标签和用户的发掘，需要对用户的行为进行深度分析来获取，这个工作便可以借助用户行为分析平台的能力，如基于用户行为模式和用户业务属性对用户进行分群分析和比较，来发现和挖掘有价值的用户标签。</p><p>另一方面，用户画像的数据，也可以和分析平台进行整合和集成，提升平台各分析模型对不同用户群的洞见能力，让分析和指标的比较更有针对性，提升数据对业务的促进能力。</p><h2 id="埋点及分析平台和-ab-试验平台如何更好的互相促进">埋点及分析平台和 A/B 试验平台如何更好的互相促进？</h2><p>A/B 测试产品是通过提供专业高效的试验平台，帮助产品进行产品决策的验证和分析。常规使用流程如下：</p><p>接入 SDK -&gt; 创建试验版本 -&gt; 设置变量、以及优化指标 -&gt; 调节试验流量 -&gt; 运行试验 -&gt; 实时监控数据进行效果评估 -&gt; 正式发布</p><p>试验平台和分析平台的 SDK 在很多功能上是重合的，在 SDK 实现上可以整合，减少业务应用接入太多 SDK 的负担。</p><p>在数据采集、建模、分析层面，分析平台可以做为 A/B 试验平台后端数据的承载，优化指标的效果评估就能覆盖用户的全量行为，无需业务及开发人员维护多个工具带来的重复埋点定义和开发工作。另外，在分析平台积累的很多分析模型和指标，在 A/B 试验平台直接可以选取使用，无需在试验平台再进行设置，除减少业务人员工作外，还能保证统计口径的一致。</p><p>反过来，A/B 试验平台的一些对比试验，以及特定灰度发布的用户群，也能整合到分析平台，通过分群分析能力，将这些群体应用到各个分析模型进行针对性的分析，甚至试验结束后，也能持续对这些用户进行追踪和分析，更好的洞察用户。</p><h2 id="如何打通产品多端的埋点数据">如何打通产品多端的埋点数据？</h2><p>目前大多数用户行为分析产品都会通过 SDK 支持 iOS、Android、Web 三个端的数据采集，还有些产品覆盖的更广，支持 PC、微信小程序、服务端、甚至直接基于 HTTP API 进行数据采集。</p><p>在分析如何打通多端用户数据前，我想先谈下单个终端的用户标识问题，毕竟，如果单个端的用户标识都不稳定，那多端用户数据打通也就失去了意义。</p><p>现在的分析产品在一般情况下，移动端会通过 SDK 生成唯一 ID 来标识用户/设备。移动化发展早期，很多采集工具用过 mac address、IDFA、android_id、IMEI 等从移动操作系统可以获取的设备软硬件信息来标识设备，但随着操作系统的发展，很多信息获取接口要么被封禁，要么已经失去了精准性。反倒是一开始就通过自己生成的 ID 来标识用户的工具，受到的影响不大，基本保持了用户/设备标识的稳定。</p><p>但这种方式有个问题，在用户卸载、重装或者刷机后，ID 信息会丢失，导致生成新的用户/设备 ID。这个问题，可以通过 ID Mapping 技术来解决：</p><p>分析平台对每个用户生成一个虚拟 ID，对同一个用户的多个设备和帐号进行映射，并绑定起来。</p><ul><li>可以通过操作系统提供的一些稳定性稍差，但短时间还比较稳定的指标，如 iOS 的 IDFA，来做 mapping。</li><li>借助分析产品的应用覆盖率，如用户是应用 A 和 B 的用户，卸载并重新安装 B 应用后，可以通过应用 A 的 ID 修复应用 B 的。</li><li>通过引入产品用户帐号体系，来做绑定，这种方式稳定性最强，但非登录匿名用户的问题不好解决。</li><li>通过 IP、Wi-Fi 信息、机器型号、甚至地理位置进行 mapping，这种方式需要用户授权更多数据获取权限，虽然是近似匹配，但当信息足够多且发散（信息熵足够大）时，也可以起到统一标识的作用。</li></ul><p>通过这个虚拟 ID 实质上就打通了产品的多端数据。实践中，ID Mapping 体系的建设工作量不小，Mapping 后用户标识如果需要发生调整，在基于事件的分析产品上需要对老数据进行重写，比较复杂。所以对于一些强帐号体系的产品，可以退化到只用用户帐号来做关联，只有非登录匿名用户才用设备 ID 来标识，这往往是性价比比较高的方案。</p><p>再引申下，在多端数据打通问题的讨论中，经常会提到用户来源归因的问题。</p><p>比如，产品做推广，使用了百度 SEM、广点通、应用市场等渠道，想知道各个渠道有多少用户激活了，以及后续使用情况如何。</p><p>为了解决这个问题，支持营销效果评估的分析平台会要求产品在平台上生成推广链接进行投放。用户在点击链接时，会从分析平台的域下做跳转再到目标页，这样就可以借助浏览器的 cookie 机制进行匹配，来对用户来源进行归因，但这种方式在移动端上面的表现不太好（iOS 已经取消了 SFSafariViewController 多应用共享 cookie 的支持）。除此之外，也可以采用 ID Mapping 提到的近似匹配技术，很多厂商声称的设备指纹技术大多也是这种，不太准，但定性分析是可以的。</p><p>一些做移动业务比较多的推广渠道，支持设备 ID 的回传功能来方便产品归因问题的解决。产品方在投放链接的时候，遵照特定格式即可。</p><p>如 <code>https://xxx.com/aaaafD?idfa=__IDFA__&amp;imei=__IMEI__</code></p><p>渠道在用户点击广告链接后，会把设备 ID 如 IDFA 或 IMEI 加到链接的内容里面，用户激活后便可以通过相应 ID 匹配来归因。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近要参加一个关于数据埋点和分析的线上讨论，这两天总结了对一些问题的思考。&lt;/p&gt;
&lt;h2 id=&quot;为什么企业需要一套完善的用户行为埋点和分析平台&quot;&gt;为什么企业需要一套完善的用户行为埋点和分析平台？&lt;/h2&gt;
&lt;p&gt;一个互联网产品从萌芽到发展壮大，离不开对用户行为的深度洞察。&lt;/p&gt;
&lt;p&gt;产品初创期间，需要分析天使用户的行为来改进产品，甚至从用户行为中得到新的思路或发现来调整产品方向；产品 growth 过程，通过对用户行为的多角度（多维）分析、对用户群体的划分以及相应行为特征的分析和比较，来指导产品设计、运营活动，并对市场渠道效果进行评估。&lt;/p&gt;
&lt;p&gt;配合上 A/B 试验平台，可以加速产品的迭代，更快得到用户的真实反馈。同时，这些数据沉淀下来，对业务的数据仓库建设、数据智能应用等方面也能起到促进作用，比如做实时推荐，需要能更快获得用户尽可能多且明细的行为数据；做用户分类、意愿预测等机器学习业务，需要清洗过的规范化、结构化的数据做 training。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Readings in Database Systems - Interactive Analytics</title>
    <link href="http://blog.zhengdong.me/2016/08/08/readings-in-database-systems-interactive-analytics/"/>
    <id>http://blog.zhengdong.me/2016/08/08/readings-in-database-systems-interactive-analytics/</id>
    <published>2016-08-08T04:04:11.000Z</published>
    <updated>2020-11-28T10:52:32.832Z</updated>
    
    <content type="html"><![CDATA[<p>最近在看 <a href="https://en.wikipedia.org/wiki/Michael_Stonebraker">Stonebraker</a> 的 <a href="http://www.redbook.io">“Readings in Database Systems”</a>, 发觉开拓了很多思路。</p><p>这么多年自己一直在从事大数据方面的工作，但除了翻过数据挖掘算法和分布式系统设计方面的论文外，完全没想过去翻翻数据库相关的论文看。现在想想，其实大数据和数据库两者很多需求和场景是一致的，要解决的问题，没准学术界很多年前就已经有方案了。</p><p>这篇文章主要是 "Interactive Analytics" 相关部分。</p><h2 id="what-is-interactive-analytics">What is Interactive Analytics</h2><p>假如你是一家电商公司的分析师，如果有 100 万用户原始交易数据打印出来摆在你面前，让你去分析这些数据的意义，你会怎么做？</p><p>如果这十万条数据给我，我估计是看不出什么东西出来。而且我相信每个人，也是如此，因为人的认知是有 bug 的，比如不能直接处理大量原始数据。</p><p>那该怎么办？</p><p>我们需要把数据通过一些方式做提炼，变成小的结果集，或者以可视化的形式展现出来。用过 <code>SQL</code> 的人也许会想到 <code>Group by</code> 语句，是的，往往通过 <code>Group by</code> 做 aggregation 后的数据，会好理解很多。</p><p><strong>大数据不只是数据量超大，更在于能从大量数据里面发现价值。</strong></p><p>而 "Interactive Analytics" 指的就是这个过程，但加了个前提：这个过程必须能在较短的时间内完成，哪怕甚至来不及遍历所有需要的原始数据。</p><p>当数据量超大的时候，这个前提对每个数据系统都是一个很大的挑战。</p><h2 id="ideas">Ideas</h2><p>那怎么让一个查询请求的执行过程比直接遍历所有依赖的数据还快呢？</p><p>结论，显而易见，只能不去遍历所有的依赖数据，能有这样的方案，那问题也就迎刃而解了。</p><p>目前靠谱的方案有两种：</p><ol type="1"><li><code>Precomputing</code>，如果预先把查询请求依赖的相关数据都做了一定的 “提炼”，便可大大减少查询需要去遍历的数据。</li><li><code>Sampling</code>，可以对数据进行取样，每次查询请求都只遍历取样后的数据，这样遍历数据也可以大大减少。</li></ol><p>“Red Book” 给出了四篇参考文献，<a href="#ref1">1</a>，<a href="#ref2">2</a>是关于 <code>Precomputing</code> 的，<a href="#ref3">3</a>，<a href="#ref4">4</a>是关于 <code>Sampling</code> 的。</p><h2 id="precomputing">Precomputing</h2><h3 id="data-cube">Data Cube</h3><p>还是以之前的交易数据举例，假如我们只关注零部件（Part）、供应商（Supplier）和客户（Customer）三个维度，关注的指标是总销售额，那么我们预先可以分别把每个不同部件 p、供应商 s、客户 c 的销售额总和统计出来，以 <code>(p, s, c)</code> 形式存起来，如果有相关查询请求，直接返回结果就可以了。</p><p>这就是一个三维 Data Cube 的建立和使用，每一个 cell 代表一种部件、供应商、客户组合 <code>(p, s, c)</code>，对应的 value 就是这个组合的销售额总计。</p><h3 id="build-data-cube">Build Data Cube</h3><p>当然，实际情况下，分析任务关注的维度肯定不仅是三个，可能是多个不同的维度组合。</p><p>对 data cube 的建立有如下三种方式：</p><ol type="1"><li>预先计算出所有组合的 data cube，之后所有的请求就可以得到最快的响应，但会带来很大的预计算和数据存储压力。（如果有 K 的维度，需要执行 <span class="math display">\[2^k\]</span> 个 Group by 语句来做预计算。）</li><li>不做任何预计算，每个请求都直接从原始数据进行提取，这种方式没有额外的数据存储压力，但数据量大的情况下请求执行耗时会非常长。</li><li>预先计算一些维度组合的 data cube，这个是 <a href="#ref1">1</a> 采取的方式，这种方式目标是做到请求执行耗时、预计算耗时和存储的平衡，但选择哪些维度组合做预计算是关键，选择错了，可能还不如采用上面两种方式。</li></ol><p>前面的例子，要全部预计算出部件、供应商和客户三个维度的 data cube，需要如下 8 个组合：</p><ol type="1"><li>psc (part, supplier, customer) (6M: 6 million rows)</li><li>pc (part, customer) (6M)</li><li>ps (part, supplier) (0.8M)</li><li>sc (supplier, customer) (6M)</li><li>p (part) (0.2M)</li><li>s (supplier) (0.01M)</li><li>c (customer) (0.1M)</li><li>none (1)</li></ol><p>（组合后面的数字代表该组合所有结果数据的行数）</p><p>可以发现，其实如果 <code>psc</code> 的数据有了，<code>pc</code> 可以通过按 <code>supplier</code> 维度汇聚 <code>psc</code> 的数据得到，<code>p</code> 可以通过按 <code>cutomer</code> 维度汇聚 <code>pc</code> 的数据得到，其他依次类推。</p><p><code>pc</code> 组合和 <code>psc</code> 组合都有 6 百万行记录，也就是对 <code>pc</code> 和 <code>psc</code> 两个维度组合进行查询都要遍历这么多行记录，那么如果不预计算 <code>pc</code>，而在用户请求 <code>pc</code> 维度时直接通过对 <code>psc</code> 维度进行汇聚，遍历的数据行数是一致的，如果以数据行数作为衡量指标，预计算 <code>pc</code> 便是毫无必要的。</p><h3 id="the-lattice-framework">The Lattice Framework</h3><p><a href="#ref1">1</a> 中提出了一个 Lattice 模型，如下图所示：</p><p><a><img src="/images/2016/the-lattice-framework.png" width="560"></a></p><p>每个节点表示一个 data cube 组合，下方的节点可以通过上方节点汇聚得到。</p><p>左边是上面例子的 lattice 模型，右边是模型之间的合并过程。</p><p>通过这样的结构，可以将维度组合选择转化为一个最优选择的问题：</p><p><em>在限制节点个数的情况下，最小化每个节点预计算的平均耗时。</em></p><p><a href="#ref1">1</a> 中首先提出了个 cost model 来评估通过依赖节点计算自身 data cube 的 cost，然后提出了个 greedy algorithm 通过计算平均最少 cost 来进行预计算维度选择，算法的细节和证明大家可以细读该<a href="http://web.eecs.umich.edu/~jag/eecs584/papers/implementing_data_cube.pdf">论文</a>。</p><p><a href="#ref2">2</a> 中给出了一种基于内存的 data cube 计算方法，有兴趣可以<a href="http://pages.cs.wisc.edu/~nil/764/DADS/38_zhao97arraybased.pdf">下载阅读</a>。</p><h2 id="sampling">Sampling</h2><p>Data Cube 模式，不论如何优化，都是需要离线任务去预先构建大量的 Cube 集，在需要的维度很多、或者数据延迟要求很低的场景下，不能很好的满足要求。</p><p>Sampling 方式是在降低准确性的前提下，减少遍历的数据量，达到快速响应查询请求的目的。</p><p><a href="#ref4">4</a> 中通过对用户的查询请求进行统计，评估出经常用的查询列集合，预先进行 Sample 创建。</p><h3 id="sample-creation">Sample Creation</h3><p>如何进行 Sample 创建，我在看论文的时候，直接想到的是将数据记录打乱，随机分布在若干个 partition 里面，当有请求过来的时候，直接选择一个或多个 partition 进行查询即可。</p><p><a href="#ref4">4</a> 中提到了这样做（<a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)#Sampling_from_a_uniform_distribution">uniform sampling</a>）的问题：</p><p><em>如果只是全局的对数据做统计，效果比较好，但如果有 filter 或者 group by 操作，这种方式往往得不到好的效果。</em></p><p>举个例子，比如我要按城市来统计销售额的分布，如果是采用我想的那种分布方式的话，一些交易量很少的城市，可能在 sample 里完全消失了，这样的分布统计，其实是错的。</p><p><a href="#ref4">4</a> 中提出了 <a href="https://en.wikipedia.org/wiki/Stratified_sampling">Stratified Sampling</a> 方式来解决这个问题。</p><p>基本思想就是首先对维度列进行统计，将相同列值的行作为一个 group，然后分别进行 sampling，论文中详细介绍了 sampling 的方法和每个 group sampling size 的设定。</p><h3 id="sample-selection">Sample Selection</h3><p>在如何选择 Sample 的问题上，<a href="#ref4">4</a> 提出了 ELP（Error Latency Profile）模型，通过用户设定的准确率和耗时要求，进行 sample 选择。</p><p>当然，这是个非常复杂的过程。<a href="#ref4">4</a> 中详细讲了如何去评估各个 Sample 的耗时和准确率，怎么样在生成执行计划的过程中考虑用户的准确率和耗时的要求。有兴趣大家可以<a href="https://sameeragarwal.github.io/blinkdb_eurosys13.pdf">详细阅读</a>。</p><p><a href="#ref3">3</a> 通过提出的如随机数据访问、在线排序、ripple join 等算法，在已有的关系型数据库，实现了一套支持 online sampling 的原型系统，有兴趣可以<a href="https://www.semanticscholar.org/paper/Informix-under-CONTROL-Online-Query-Processing-Hellerstein-Avnur/367845b3e2f4dd6e36d7725a579575f8855d9737/pdf">详细阅读</a>。</p><h2 id="summary">Summary</h2><p>Data Cube 方案，在数据的准确度方面是毋须质疑优于 Sampling 方案的，工程界的 <a href="http://kylin.apache.org">Apache Kylin</a> 就是如此的方式。而 Sampling 方式目前的应用还比较少，对于很多用户而言，Sampling 的方案即使是 99% 的准确度，还是无法接受的，哪怕其实已经满足了他的需求。</p><p>但我倒比较看好 Sampling 方式，因为 Data Cube 的整个机制对数据变化和实时方面有很大的限制，随着内存越来越廉价，以及越来越好的列存储方案，数据进行实时交互分析变得越来越可行，比如 <a href="http://impala.io">Impala</a> 和 <a href="https://prestodb.io">Presto</a>，在大数据量的情况下，性能都很好，不大的集群都可以做到秒级响应对亿级数据量的查询。</p><p>当然，资源不可能是无限的，也不可能每个查询请求都能有资源保证快速遍历海量数据，所以，通过对准确率方面的牺牲，达到查询耗时的降低，其实是一种比较经济的方案 (Presto 是有类似 <a href="#ref4">4</a> 中提到的 Sampling 方案）。</p><p>Reference</p><p><a name="ref1">[1] Venky Harinarayan, Anand Rajaraman, Jeffrey D. Ullman. Implementing Data Cubes Efficiently. SIGMOD, 1996.</a></p><p><a name="ref2">[2] Yihong Zhao, Prasad M. Deshpande, Jeffrey F. Naughton. An Array-Based Algorithm for Simultaneous Multidimensional Aggregates. SIGMOD, 1997.</a></p><p><a name="ref3">[3] Joseph M. Hellerstein, Ron Avnur, Vijayshankar Raman. Informix under CONTROL: Online Query Processing. Data Mining and Knowledge Discovery, 4(4), 2000, 281-314.</a></p><p><a name="ref4">[4] Sameer Agarwal, Barzan Mozafari, Aurojit Panda, Henry Milner, Samuel Madden, Ion Stoica. BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data. EuroSys, 2013.</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在看 &lt;a href=&quot;https://en.wikipedia.org/wiki/Michael_Stonebraker&quot;&gt;Stonebraker&lt;/a&gt; 的 &lt;a href=&quot;http://www.redbook.io&quot;&gt;“Readings in Database Systems”&lt;/a&gt;, 发觉开拓了很多思路。&lt;/p&gt;
&lt;p&gt;这么多年自己一直在从事大数据方面的工作，但除了翻过数据挖掘算法和分布式系统设计方面的论文外，完全没想过去翻翻数据库相关的论文看。现在想想，其实大数据和数据库两者很多需求和场景是一致的，要解决的问题，没准学术界很多年前就已经有方案了。&lt;/p&gt;
&lt;p&gt;这篇文章主要是 &quot;Interactive Analytics&quot; 相关部分。&lt;/p&gt;
&lt;h2 id=&quot;what-is-interactive-analytics&quot;&gt;What is Interactive Analytics&lt;/h2&gt;
&lt;p&gt;假如你是一家电商公司的分析师，如果有 100 万用户原始交易数据打印出来摆在你面前，让你去分析这些数据的意义，你会怎么做？&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>A Bug in a Java Servlet</title>
    <link href="http://blog.zhengdong.me/2014/06/20/a-bug-in-a-java-servlet/"/>
    <id>http://blog.zhengdong.me/2014/06/20/a-bug-in-a-java-servlet/</id>
    <published>2014-06-20T03:47:33.000Z</published>
    <updated>2020-11-28T10:52:32.830Z</updated>
    
    <content type="html"><![CDATA[<p>We have a legacy system, which is a web service, receives HTTP POST from clients, parses the data, then stores them in a file.</p><p>The function of the system is simple, and people already done functional and performance test, it's stable. As time drifted away, the system was <a href="http://en.wikipedia.org/wiki/Copy_and_paste_programming">copy and paste</a> to some projects by only changing the data parsing logic.</p><p>I had a similar requirement recently, then I delved into the legacy code to check if it works in order to not <a href="http://en.wikipedia.org/wiki/Reinventing_the_wheel">reinventing the wheel</a>.</p><h2 id="wtf">WTF</h2><p>At first, I noticed below code in a <code>HttpServlet</code> class, it allocates more than 1M memory for each HTTP POST request.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> MAX_CONTENT_LENGTH = <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> BUFFER_SIZE = <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">       <span class="keyword">int</span> requestContentBufSize = request.getContentLength() + MAX_CONTENT_LENGTH;</span><br><span class="line">       ByteBuffer requestContentBuf = ByteBuffer.allocate(requestContentBufSize);</span><br><span class="line">       <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[BUFFER_SIZE];</span><br><span class="line">       requestInputStream = <span class="keyword">new</span> DataInputStream(request.getInputStream());</span><br><span class="line">       <span class="keyword">int</span> readBytes = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">int</span> totalReadBytes = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">while</span> ((readBytes = requestInputStream.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">           requestContentBuf.put(buffer);</span><br><span class="line">    totalReadBytes = totalReadBytes + readBytes;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">byte</span>[] requestContent = Arrays.copyOf(requestContentBuf.array(), totalReadBytes);</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>It's insane, I believe the memory should be the same as each HTTP POST body size. Then I changed the code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> requestContentBufSize = request.getContentLength();</span><br></pre></td></tr></table></figure><p>Deployed the service and sent one HTTP POST request to it.</p><p><code>curl -d 'Hello, World' http://my.server.com:9000/log</code></p><p>An <code>Exception</code> occurred.</p><h2 id="the-bufferoverflowexception">The BufferOverflowException</h2><p>After reducing the memory allocated for <code>ByteBuffer</code>, it overflows.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">java.nio.BufferOverflowException</span><br><span class="line">at java.nio.HeapByteBuffer.put(HeapByteBuffer.java:183)</span><br><span class="line">at java.nio.ByteBuffer.put(ByteBuffer.java:830)</span><br><span class="line">at com.myproject.servlet.LogServer.doPost(LogServer.java:99)</span><br><span class="line">at javax.servlet.http.HttpServlet.service(HttpServlet.java:643)</span><br><span class="line">at javax.servlet.http.HttpServlet.service(HttpServlet.java:723)</span><br><span class="line">at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)</span><br><span class="line">at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)</span><br><span class="line">at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)</span><br><span class="line">at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)</span><br><span class="line">at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)</span><br><span class="line">at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)</span><br><span class="line">at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)</span><br><span class="line">at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)</span><br><span class="line">at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861)</span><br><span class="line">at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606)</span><br><span class="line">at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)</span><br><span class="line">at java.lang.Thread.run(Thread.java:701)</span><br></pre></td></tr></table></figure><p>I thought I'd better dig into how does the servlet do to make <code>ByteBuffer</code> get its data?</p><ol type="1"><li>It creates a small buffer occupied <code>BUFFER_SIZE</code> (4096) bytes.</li><li>It iterates the HTTP request input stream, to put the data into the small buffer.</li><li>It puts the small buffer to <code>ByteBuffer</code> and loop back to <code>1</code>.</li></ol><p>Well, in the last loop, the data read from the HTTP request input stream might smaller than the <code>BUFFER_SIZE</code>, but the servlet still puts <code>BUFFER_SIZE</code> bytes to <code>ByteBuffer</code>.</p><p>Then, to fix the <code>ExceptionBufferOverflowException</code>, I increased the capacity of previous <code>ByteBuffer</code> by <code>BUFFER_SIZE</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> requestContentBufSize = request.getContentLength() + BUFFER_SIZE;</span><br></pre></td></tr></table></figure><p>Deployed again, and</p><p><code>curl -d 'Hello, World' http://my.server.com:9000/log</code></p><p>The bug was fixed.</p><p>Did I?</p><h2 id="the-servletinputstream">The ServletInputStream</h2><p>When client posts huge data, what could happen?</p><p>I created a String which is 7516 bytes, and sent to server.</p><p><code>curl -d 'very very long string' http://my.server.com:9000/log</code></p><p>Sometimes, the <code>java.nio.BufferOverflowException</code> occurred, and sometimes it didn't.</p><p>What went wrong?</p><p>To find the root cause, I added some logs to trace the <code>ByteBuffer</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">int</span> requestContentBufSize = request.getContentLength() + BUFFER_SIZE;</span><br><span class="line">  ByteBuffer requestContentBuf = ByteBuffer.allocate(requestContentBufSize);</span><br><span class="line">  <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[BUFFER_SIZE];</span><br><span class="line">  requestInputStream = <span class="keyword">new</span> DataInputStream(request.getInputStream());</span><br><span class="line">  <span class="keyword">int</span> readBytes = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> totalReadBytes = <span class="number">0</span>;</span><br><span class="line">  log.debug(<span class="string">&quot;1: ByteBuffer position: &quot;</span> + requestContentBuf.position() +</span><br><span class="line">          <span class="string">&quot;, buffer capacity: &quot;</span> + requestContentBuf.capacity() +</span><br><span class="line">          <span class="string">&quot;, buffer remaining: &quot;</span> + requestContentBuf.remaining());</span><br><span class="line">  <span class="keyword">while</span> ((readBytes = requestInputStream.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">requestContentBuf.put(buffer);</span><br><span class="line">totalReadBytes = totalReadBytes + readBytes;</span><br><span class="line">      log.debug(<span class="string">&quot;2. Bytes read: &quot;</span> + readBytes);</span><br><span class="line">      log.debug(<span class="string">&quot;1: ByteBuffer position: &quot;</span> + requestContentBuf.position() +</span><br><span class="line">              <span class="string">&quot;, buffer capacity: &quot;</span> + requestContentBuf.capacity() +</span><br><span class="line">              <span class="string">&quot;, buffer remaining: &quot;</span> + requestContentBuf.remaining());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>The log printed when no exception,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 1: ByteBuffer position: 0, buffer capacity: 11612, buffer remaining: 11612</span><br><span class="line">- 2. Bytes read: 4096</span><br><span class="line">- 1: ByteBuffer position: 4096, buffer capacity: 11612, buffer remaining: 7516</span><br><span class="line">- 2. Bytes read: 3420</span><br><span class="line">- 1: ByteBuffer position: 8192, buffer capacity: 11612, buffer remaining: 3420</span><br></pre></td></tr></table></figure><p>The log printed when exception occurred,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 1: ByteBuffer position: 0, buffer capacity: 11612, buffer remaining: 11612</span><br><span class="line">- 2. Bytes read: 1356</span><br><span class="line">- 1: ByteBuffer position: 4096, buffer capacity: 11612, buffer remaining: 7516</span><br><span class="line">- 2. Bytes read: 1356</span><br><span class="line">- 1: ByteBuffer position: 8192, buffer capacity: 11612, buffer remaining: 3420</span><br></pre></td></tr></table></figure><p>Now, it is easy to find out the root cause is in these lines of code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ((readBytes = requestInputStream.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    requestContentBuf.put(buffer);</span><br></pre></td></tr></table></figure><p>The <code>read</code> method call won't put data to the <code>buffer</code> fully which was specified as 4096 bytes even when the input stream still has data.</p><p>And to fix it, just specify the offset and length of the small <code>buffer</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ((readBytes = requestInputStream.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    requestContentBuf.put(buffer, <span class="number">0</span>, readBytes);</span><br></pre></td></tr></table></figure><p>I had increased the capacity of the <code>ByteBuffer</code> by <code>BUFFER_SIZE</code>, this change should also be reverted.</p><p>Now, the bug is fixed, and this is network programming.</p><h2 id="questions">Questions</h2><p>"The system works a long time, and it shouldn't have this problem or we knew it long ago"</p><blockquote><p>This is because the client seldom posts data more than 4096 bytes to server.</p></blockquote><p>"I have read the Javadoc of <code>DataInputStream</code>, the <code>read</code> method will put data fully to the specified buffer"</p><blockquote><p>It didn't, please read it again.</p></blockquote><p>"I have tested the <code>read</code> method of <code>DataInputStream</code> on a file, it reads fully 4096 bytes in every iteration"</p><blockquote><p>This is a web service, deploy it to a server and test.</p></blockquote><p>"I have tested it on my local machine as a web service, and it reads fully 4096 bytes in every iteration"</p><blockquote><p>This is a web service, it should be in a network.</p></blockquote><h2 id="at-last">At Last</h2><p>When a potential bug was reported, we do tests to make it happen again and find the root cause.</p><p>We do not stop listening and just look for reasons to reject it.</p><p>When we find a bug, we do help others to make it reappear to collect information.</p><p>We do not sit there and just blame on others for their mistakes.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;We have a legacy system, which is a web service, receives HTTP POST from clients, parses the data, then stores them in a file.&lt;/p&gt;
&lt;p&gt;The function of the system is simple, and people already done functional and performance test, it&#39;s stable. As time drifted away, the system was &lt;a href=&quot;http://en.wikipedia.org/wiki/Copy_and_paste_programming&quot;&gt;copy and paste&lt;/a&gt; to some projects by only changing the data parsing logic.&lt;/p&gt;
&lt;p&gt;I had a similar requirement recently, then I delved into the legacy code to check if it works in order to not &lt;a href=&quot;http://en.wikipedia.org/wiki/Reinventing_the_wheel&quot;&gt;reinventing the wheel&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;wtf&quot;&gt;WTF&lt;/h2&gt;
&lt;p&gt;At first, I noticed below code in a &lt;code&gt;HttpServlet&lt;/code&gt; class, it allocates more than 1M memory for each HTTP POST request.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>TDD on Swift</title>
    <link href="http://blog.zhengdong.me/2014/06/16/tdd-on-swift/"/>
    <id>http://blog.zhengdong.me/2014/06/16/tdd-on-swift/</id>
    <published>2014-06-15T16:26:26.000Z</published>
    <updated>2020-11-28T10:52:32.829Z</updated>
    
    <content type="html"><![CDATA[<p>Long long ago, I wrote a post about <a href="/2011/01/16/tdd-using-objective-c">how to do TDD using Objective-C</a>, since <a href="http://www.apple.com/apple-events/june-2014/">Apple WWDC 2014</a>, <a href="https://developer.apple.com/swift/">Swift</a> is really eye-catching, I think I should write a new one to follow the trend.</p><p><a href="https://developer.apple.com/library/ios/documentation/ToolsLanguages/Conceptual/Xcode_Overview/UnitTestYourApp/UnitTestYourApp.html">XCTest</a> is used as the unit test framework, and Xcode 6 is needed.</p><h2 id="tdd-work-flow">TDD Work-flow</h2><ol type="1"><li>Add a test for a user case or a user story</li><li>Run all tests and see if the new one fails</li><li>Write some code that causes the test to pass</li><li>Run tests, change production code until all test cases pass</li><li>Refactor the production code</li><li>Refactor the test code</li><li>Return to 1, and repeat</li></ol><p>The <code>5</code> and <code>6</code> are optional, do them only if needed, but be sure that DO NOT do them at the same time. That is, when you refactor production code, you can't change the test code, until all the test cases are passed, then you are confident that your production code refactoring is perfect, then, you can refactor the test code, and this time, you can't change the production code.</p><h2 id="a-simple-example">A Simple Example</h2><p>We are about to implement a super simple bank account management tool.</p><h3 id="create-a-project">Create a Project</h3><p>Use Xcode to create a project <code>BankAccount</code> (iOS Single View Application)</p><p><img src="/images/2014/tddswift1.png" width="500"></p><h3 id="add-a-test-case">Add a Test Case</h3><p>Create a Swift file named <code>SavingAccountTest</code>, and choose <code>BankAccountTests</code> as target.</p><p><img src="/images/2014/tddswift2.png" width="500"></p><p>"People can deposit money to a saving account", it's our first user story.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Foundation</span><br><span class="line"><span class="keyword">import</span> XCTest</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SavingAccountTest</span>: <span class="title">XCTestCase</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">testDeposit</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">var</span> account = <span class="type">SavingAccount</span>()</span><br><span class="line">        account.deposit(<span class="number">100</span>)</span><br><span class="line">        <span class="type">XCTAssertEqual</span>(<span class="number">100</span>, account.balance)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-all-tests">Run All Tests</h3><p>Run all the unit tests, it fails as we expected.</p><p><img src="/images/2014/tddswift3.png" width="500"></p><h3 id="write-code-to-pass-the-test">Write Code to Pass the Test</h3><p>Create a Swift file named <code>SavingAccount</code>, and choose both <code>BankAccount</code> and <code>BankAccountTests</code> as targets.</p><p>Make it simple, just to pass the test.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Foundation</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SavingAccount</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> balance:<span class="type">Int</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">deposit</span><span class="params">(money:Int)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-all-tests-1">Run All Tests</h3><p>It passes.</p><p><img src="/images/2014/tddswift4.png" width="500"></p><h3 id="next-user-story">Next User Story?</h3><p>"People could withdraw some money"</p><p>Let's change the <code>testDeposit</code> test case.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Foundation</span><br><span class="line"><span class="keyword">import</span> XCTest</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SavingAccountTest</span>: <span class="title">XCTestCase</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">testDepositAndWithdraw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">var</span> account = <span class="type">SavingAccount</span>()</span><br><span class="line">        account.deposit(<span class="number">100</span>)</span><br><span class="line">        account.withdraw(<span class="number">50</span>)</span><br><span class="line">        <span class="type">XCTAssertEqual</span>(<span class="number">50</span>, account.balance)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Also, add an empty <code>withdraw</code> method to <code>SavingAccount</code> to satisfy the compiler. Do not add any other code until we see it fails.</p><h3 id="run-all-tests-2">Run All Tests</h3><p>The test fails, because the account balance was not updated after people withdrew some money.</p><p><img src="/images/2014/tddswift5.png" width="500"></p><h3 id="write-code-to-support-withdraw">Write Code to Support Withdraw</h3><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Foundation</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SavingAccount</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> balance:<span class="type">Int</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">deposit</span><span class="params">(money:Int)</span></span> &#123;</span><br><span class="line">        balance += money</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">withdraw</span><span class="params">(money:Int)</span></span> &#123;</span><br><span class="line">        balance -= money</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-all-tests-3">Run All Tests</h3><p>All the user stories are satisfied.</p><p><img src="/images/2014/tddswift6.png" width="500"></p><h3 id="any-other-new-user-story">Any Other New User Story?</h3><p>"People can't withdraw money beyond their account balance"</p><p>We add a new test case <code>testNegativeBalanceIsNotFine</code></p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">testNegativeBalanceIsNotFine</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> account = <span class="type">SavingAccount</span>()</span><br><span class="line">    account.deposit(<span class="number">50</span>)</span><br><span class="line">    account.withdraw(<span class="number">100</span>)</span><br><span class="line">    <span class="type">XCTAssertEqual</span>(<span class="number">0</span>, account.balance)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-all-tests-4">Run All Tests</h3><p>It fails, we have to fix it.</p><p><img src="/images/2014/tddswift7.png" width="500"></p><h3 id="write-code">Write Code</h3><p>Change the <code>withdraw</code> method, set account balance to 0 if it is less than 0.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">withdraw</span><span class="params">(money:Int)</span></span> &#123;</span><br><span class="line">    balance -= money</span><br><span class="line">    <span class="keyword">if</span> balance &lt; <span class="number">0</span> &#123;</span><br><span class="line">        balance = <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="run-all-tests-5">Run All Tests</h3><p>All right, all the test cases are succeeded.</p><p><img src="/images/2014/tddswift8.png" width="500"></p><h3 id="refactoring">Refactoring</h3><p>Until now, we haven't do any refactoring on our code base.</p><p>I think the production code is fine, so we skip the step 5, and refactor the test code.</p><p>We can see that both test cases create an instance of <code>SavingAccount</code>, the duplicated code can be removed by using only one <code>SavingAccount</code> instance.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SavingAccountTest</span>: <span class="title">XCTestCase</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> account = <span class="type">SavingAccount</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">testDepositAndWithdraw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        account.deposit(<span class="number">100</span>)</span><br><span class="line">        account.withdraw(<span class="number">50</span>)</span><br><span class="line">        <span class="type">XCTAssertEqual</span>(<span class="number">50</span>, account.balance)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">func</span> <span class="title">testNegativeBalanceIsNotFine</span><span class="params">()</span></span> &#123;</span><br><span class="line">        account.deposit(<span class="number">50</span>)</span><br><span class="line">        account.withdraw(<span class="number">100</span>)</span><br><span class="line">        <span class="type">XCTAssertEqual</span>(<span class="number">0</span>, account.balance)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Don't forget to run all the tests, make sure it is succeeded.</p><h3 id="why-no-setup-and-teardown">Why no setup and tearDown</h3><p>People coming from <code>objc</code> may doubt that why the <code>account</code> instance is not put into <code>setUp</code> method, the way we use might cause different test cases sharing one instance variable, as we know, test cases should be independent with each other.</p><p>Yes, I had this doubt, too. So I did a test, by adding a "account balance should be 0" check before each test cases.</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">testDepositAndWithdraw</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="type">XCTAssertEqual</span>(<span class="number">0</span>, account.balance)</span><br><span class="line">    account.deposit(<span class="number">100</span>)</span><br><span class="line">    account.withdraw(<span class="number">50</span>)</span><br><span class="line">    <span class="type">XCTAssertEqual</span>(<span class="number">50</span>, account.balance)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">testNegativeBalanceIsNotFine</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="type">XCTAssertEqual</span>(<span class="number">0</span>, account.balance)</span><br><span class="line">    account.deposit(<span class="number">50</span>)</span><br><span class="line">    account.withdraw(<span class="number">100</span>)</span><br><span class="line">    <span class="type">XCTAssertEqual</span>(<span class="number">0</span>, account.balance)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The result shows that the <code>XCTest</code> framework avoids instance variable sharing between test cases by instantiating a brand new <code>XCTestCase</code> object for each test case. That is, it instantiated two <code>SavingAccountTest</code> objects as our tests run.</p><h2 id="to-tdd-haters">To TDD Haters</h2><p>If you hate TDD, and may think this blog post is garbage.</p><p>Sorry for that, you can remove your browser history of this address, if it makes you feel better.</p><p>Also, I strongly recommend you to watch the "TDD dead" <a href="https://www.youtube.com/watch?v=z9quxZsLcfo">discussions</a> by <a href="http://martinfowler.com">Martin Fowler</a>, <a href="http://www.threeriversinstitute.org/Kent%20Beck.htm">Kent Beck</a> and <a href="http://david.heinemeierhansson.com">David Heinemeier Hansson</a>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Long long ago, I wrote a post about &lt;a href=&quot;/2011/01/16/tdd-using-objective-c&quot;&gt;how to do TDD using Objective-C&lt;/a&gt;, since &lt;a href=&quot;http://www.apple.com/apple-events/june-2014/&quot;&gt;Apple WWDC 2014&lt;/a&gt;, &lt;a href=&quot;https://developer.apple.com/swift/&quot;&gt;Swift&lt;/a&gt; is really eye-catching, I think I should write a new one to follow the trend.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.apple.com/library/ios/documentation/ToolsLanguages/Conceptual/Xcode_Overview/UnitTestYourApp/UnitTestYourApp.html&quot;&gt;XCTest&lt;/a&gt; is used as the unit test framework, and Xcode 6 is needed.&lt;/p&gt;
&lt;h2 id=&quot;tdd-work-flow&quot;&gt;TDD Work-flow&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Add a test for a user case or a user story&lt;/li&gt;
&lt;li&gt;Run all tests and see if the new one fails&lt;/li&gt;
&lt;li&gt;Write some code that causes the test to pass&lt;/li&gt;
&lt;li&gt;Run tests, change production code until all test cases pass&lt;/li&gt;
&lt;li&gt;Refactor the production code&lt;/li&gt;
&lt;li&gt;Refactor the test code&lt;/li&gt;
&lt;li&gt;Return to 1, and repeat&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;code&gt;5&lt;/code&gt; and &lt;code&gt;6&lt;/code&gt; are optional, do them only if needed, but be sure that DO NOT do them at the same time. That is, when you refactor production code, you can&#39;t change the test code, until all the test cases are passed, then you are confident that your production code refactoring is perfect, then, you can refactor the test code, and this time, you can&#39;t change the production code.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
